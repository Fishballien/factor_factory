# -*- coding: utf-8 -*-
"""
Created on Tue Nov 19 17:14:02 2024

@author: Xintang Zheng

æ˜Ÿæ˜Ÿ: â˜… â˜† âœª âœ© ğŸŒŸ â­ âœ¨ ğŸŒ  ğŸ’« â­ï¸
å‹¾å‹¾å‰å‰: âœ“ âœ” âœ• âœ– âœ… â
æŠ¥è­¦å•¦: âš  â“˜ â„¹ â˜£
ç®­å¤´: â” âœ â™ â¤ â¥ â†© â†ª
emoji: ğŸ”” â³ â° ğŸ”’ ğŸ”“ ğŸ›‘ ğŸš« â— â“ âŒ â­• ğŸš€ ğŸ”¥ ğŸ’§ ğŸ’¡ ğŸµ ğŸ¶ ğŸ§­ ğŸ“… ğŸ¤” ğŸ§® ğŸ”¢ ğŸ“Š ğŸ“ˆ ğŸ“‰ ğŸ§  ğŸ“

"""
# %%
import os
os.environ["NUMBA_NUM_THREADS"] = "100"


# %%
from pathlib import Path
import pandas as pd
from functools import partial
from tqdm import tqdm
from concurrent.futures import ProcessPoolExecutor, as_completed
import yaml
import traceback
import warnings
warnings.filterwarnings("ignore")


from utils.datautils import add_dataframe_to_dataframe_reindex, check_dataframe_consistency
from utils.dirutils import load_path_config, list_parquet_files
from trans_operators import *
from utils.param import para_allocation
from utils.naming import generate_factor_names


# %%
class GenerateFactors:
    
    def __init__(self, generate_name, org_name, ind_cate, factor_list=None, org_dir=None, target_dir=None, n_workers=1, mode='init'):
        self.generate_name = generate_name
        self.org_name = org_name
        self.ind_cate = ind_cate
        self.factor_list = factor_list
        self.n_workers = n_workers
        self.mode = mode
        self.org_dir_input = org_dir
        self.target_dir_input = target_dir
        
        self._load_path_config()
        self._load_param()
        self._init_dir()
        self._get_ts_mapping()
        self._get_factor_list()
        self._get_generate_one_func()
        
    def _load_path_config(self):
        project_dir = Path(__file__).resolve().parents[1]
        path_config = load_path_config(project_dir)
        
        self.factor_dir = Path(path_config['factors'])
        self.param_dir = Path(path_config['param'])
        
    def _init_dir(self):
        # å¦‚æœæŒ‡å®šäº†org_dirå’Œtarget_diråˆ™ä½¿ç”¨ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
        if self.org_dir_input is not None:
            self.org_dir = Path(self.org_dir_input)
        else:
            self.org_dir = self.factor_dir / self.ind_cate / self.org_name
            
        if self.target_dir_input is not None:
            self.target_dir = Path(self.target_dir_input)
        else:
            self.target_dir = self.factor_dir / self.ind_cate / f'{self.org_name}_TS_{self.generate_name}'
            
        self.target_dir.mkdir(exist_ok=True, parents=True)
        self.debug_dir = self.target_dir / 'debug'
        self.debug_dir.mkdir(exist_ok=True, parents=True)
        
    def _load_param(self):
        with open(self.param_dir / 'ts' / f'{self.generate_name}.yaml', "r") as file:
            self.params = yaml.safe_load(file)

    def _get_ts_mapping(self):
        ts_info = self.params['ts']
        
        # å¤„ç†ç¬¬ä¸€å±‚æ—¶åºå˜æ¢
        ts_mapping = {}
        ts_name_groups = {}  # å­˜å‚¨æŒ‰åŸºç¡€è½¬æ¢å‡½æ•°ååˆ†ç»„çš„ts_pr_names
        
        for ts_name, ts_prs in ts_info.items():
            ts_pr_names = generate_factor_names(ts_name, ts_prs) if len(ts_prs) > 0 else [ts_name]
            ts_pr_list = para_allocation(ts_prs) if len(ts_prs) > 0 else [{}]
            ts_func = globals()[ts_name]
            
            # æŒ‰åŸºç¡€å‡½æ•°åï¼ˆå¦‚'stdz', 'ma'ç­‰ï¼‰åˆ†ç»„å­˜å‚¨æ‰€æœ‰å‚æ•°ç»„åˆ
            ts_name_groups[ts_name] = []
            
            for ts_pr_name, ts_pr in zip(ts_pr_names, ts_pr_list):
                full_name = ts_pr_name
                ts_mapping[full_name] = partial(ts_func, **ts_pr)
                ts_name_groups[ts_name].append(full_name)
        
        self.ts_mapping = ts_mapping
        
    def _get_generate_one_func(self):
        self.generate_one = partial(generate_ts_transform,
                                    org_dir=self.org_dir,
                                    target_dir=self.target_dir,
                                    ts_mapping=self.ts_mapping,
                                    debug_dir=self.debug_dir)
        
    def _get_factor_list(self):
        self.factor_list = self.factor_list or list_parquet_files(self.org_dir)
        
    def run(self):
        if self.n_workers is None or self.n_workers == 1:
            for factor_name in self.factor_list:
                self.generate_one(factor_name)
        else:
            with ProcessPoolExecutor(max_workers=self.n_workers) as executor:
                all_tasks = [executor.submit(self.generate_one, factor_name)
                             for factor_name in self.factor_list]
                num_of_success = 0
                for task in tqdm(as_completed(all_tasks), total=len(all_tasks), desc=f'{self.org_name}_TS_{self.generate_name}'):
                    res = task.result()
                    if res == 0:
                        num_of_success += 1
                print(f'num_of_success: {num_of_success}, num_of_failed: {len(self.factor_list)-num_of_success}')


# %%
def generate_ts_transform(org_factor_name, org_dir, target_dir, ts_mapping, debug_dir=Path('./debug')):
    """
    åªå¯¹åŸå§‹å› å­è¿›è¡Œæ—¶åºå˜æ¢ï¼Œä¸åšèšåˆæ“ä½œ
    
    å‚æ•°:
    - org_factor_name: åŸå§‹å› å­åç§°
    - org_dir: åŸå§‹å› å­å­˜å‚¨ç›®å½•
    - target_dir: ç›®æ ‡è¾“å‡ºç›®å½•(æ—¶åºå˜æ¢ç»“æœä¿å­˜ä½ç½®)
    - ts_mapping: æ—¶åºå˜æ¢æ˜ å°„
    - debug_dir: è°ƒè¯•ä¿¡æ¯ç›®å½•
    """
    try:
        # ä»org_diråŠ è½½æŒ‡å®šçš„åŸå§‹å› å­
        org_factor_path = org_dir / f'{org_factor_name}.parquet'
        factor = pd.read_parquet(org_factor_path)
        # print(f"Loading factor from {org_factor_path}")
    except Exception as e:
        print(f"Error loading factor {org_factor_name}: {e}")
        return 1
    
    # ç¡®ä¿æ•°æ®ç±»å‹ä¸ºfloat32å¹¶åˆ é™¤å…¨NAçš„è¡Œ
    factor = to_float32(factor).dropna(how='all')
    
    # ç›´æ¥å¤„ç†æ—¶åºå˜æ¢ï¼Œåªåšä¸€å±‚å˜æ¢
    process_ts(factor, org_factor_name, ts_mapping, target_dir, debug_dir)
    
    return 0


def process_ts_task(ts_name, factor, factor_name, target_dir, ts_func, debug_dir=Path('./debug')):
    """
    å•ä¸ªæ—¶åºå˜æ¢ä»»åŠ¡çš„å¤„ç†å‡½æ•°ï¼Œæ·»åŠ ä¸€è‡´æ€§æ£€æŸ¥
    
    å‚æ•°:
    - ts_name: æ—¶åºå˜æ¢åç§°
    - factor: åŸå§‹å› å­æ•°æ®
    - factor_name: å› å­åç§°
    - target_dir: ç›®æ ‡è¾“å‡ºç›®å½•
    - ts_func: æ—¶åºå˜æ¢å‡½æ•°
    - debug_dir: è°ƒè¯•ä¿¡æ¯ç›®å½•
    """
    try:
        # è®¡ç®—æ—¶åºå˜æ¢ç»“æœ
        factor_ts = ts_func(factor)
        
        # å®šä¹‰è¾“å‡ºè·¯å¾„
        output_path = target_dir / f'{factor_name}-{ts_name}.parquet'
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å·²æœ‰çš„å› å­æ•°æ®
        if os.path.exists(output_path):
            # è¯»å–å·²æœ‰çš„å› å­æ•°æ®
            existing_factor_ts = pd.read_parquet(output_path)
            
            # æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
            status, info = check_dataframe_consistency(existing_factor_ts, factor_ts)
            
            if status == "INCONSISTENT":
                # å°†ä¸ä¸€è‡´çš„æ–°æ•°æ®ä¿å­˜åˆ°debugç›®å½•
                debug_path = debug_dir / f'{factor_name}-{ts_name}-inconsistent.parquet'
                factor_ts.to_parquet(debug_path)
                
                # æŠ¥é”™
                error_msg = (f"Data inconsistency detected for factor {factor_name}-{ts_name}: "
                            f"At index {info['index']}, column {info['column']}, "
                            f"original value: {info['original_value']}, new value: {info['new_value']}. "
                            f"Total {info['inconsistent_count']} inconsistencies found. "
                            f"Debug data saved to {debug_path}")
                print(error_msg)
                return False  # è¿”å›å¤±è´¥çŠ¶æ€
            else:
                # æ•°æ®ä¸€è‡´ï¼Œè¿›è¡Œæ›´æ–°ï¼ˆæ·»åŠ æ–°æ•°æ®ï¼‰
                factor_ts = add_dataframe_to_dataframe_reindex(existing_factor_ts, factor_ts)
        
        # ä¿å­˜ç»“æœ
        factor_ts.to_parquet(output_path)
        return True  # è¿”å›æˆåŠŸçŠ¶æ€
        
    except Exception as e:
        traceback.print_exc()
        print(f"Error processing {ts_name} for {factor_name}: {e}")
        return False  # è¿”å›å¤±è´¥çŠ¶æ€


def process_ts(factor, factor_name, ts_mapping, target_dir, debug_dir):
    """
    ä½¿ç”¨å¤šè¿›ç¨‹å¤„ç† ts_mapping ä¸­çš„ä»»åŠ¡ã€‚
    
    Args:
        factor: è¾“å…¥å› å­æ•°æ®ã€‚
        factor_name: å› å­åç§°ã€‚
        ts_mapping: æ—¶é—´åºåˆ—æ˜ å°„ï¼Œé”®ä¸ºåç§°ï¼Œå€¼ä¸ºå¤„ç†å‡½æ•°ã€‚
        target_dir: è¾“å‡ºç›®å½•ã€‚
    """
    # åŠ¨æ€åˆ†é…è¿›ç¨‹æ•°
    max_workers = min(len(ts_mapping), 200)

    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        futures = []
        for ts_name, ts_func in ts_mapping.items():
            # ä½¿ç”¨ partial ç”Ÿæˆæ–°å‡½æ•°ï¼Œç»‘å®š ts_func
            task_func = partial(process_ts_task, ts_name, factor, factor_name, target_dir, ts_func, debug_dir)
            # æäº¤ä»»åŠ¡åˆ°è¿›ç¨‹æ± 
            futures.append(executor.submit(task_func))

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for future in futures:
            try:
                future.result()  # æ•è·å¼‚å¸¸
            except Exception as e:
                print(f"Error processing {future}: {e}")

