 # -*- coding: utf-8 -*-
"""
Created on Wed Nov 27 16:52:45 2024

@author: Xintang Zheng

æ˜Ÿæ˜Ÿ: â˜… â˜† âœª âœ© ğŸŒŸ â­ âœ¨ ğŸŒ  ğŸ’« â­ï¸
å‹¾å‹¾å‰å‰: âœ“ âœ” âœ• âœ– âœ… â
æŠ¥è­¦å•¦: âš  â“˜ â„¹ â˜£
ç®­å¤´: â” âœ â™ â¤ â¥ â†© â†ª
emoji: ğŸ”” â³ â° ğŸ”’ ğŸ”“ ğŸ›‘ ğŸš« â— â“ âŒ â­• ğŸš€ ğŸ”¥ ğŸ’§ ğŸ’¡ ğŸµ ğŸ¶ ğŸ§­ ğŸ“… ğŸ¤” ğŸ§® ğŸ”¢ ğŸ“Š ğŸ“ˆ ğŸ“‰ ğŸ§  ğŸ“

"""
# %% imports
import pandas as pd
import numpy as np
from numba import jit
from numba import njit, prange


from utils.timeutils import get_num_of_bars


# %%
def dod(df, n):
    """
    è®¡ç®—æ¯ä¸ªæ—¶é—´æˆ³ä¸Šçš„å€¼ä¸ºå½“å‰æ—¶é—´æˆ³æ•°æ®é™¤ä»¥å‰nå¤©åŒä¸€æ—¶é—´æˆ³çš„æ•°æ®ã€‚

    å‚æ•°ï¼š
    df (pd.DataFrame): datetimeä¸ºindexçš„æ•°æ®æ¡†ã€‚
    n (int): é—´éš”å¤©æ•°ã€‚

    è¿”å›ï¼š
    pd.DataFrame: è®¡ç®—åçš„æ•°æ®æ¡†ã€‚
    """
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("DataFrameçš„indexå¿…é¡»æ˜¯DatetimeIndexç±»å‹")
    
    result = (df / df.shift(n, freq='D')).reindex(df.index)
    
    return result


def dod_three_minutes(df, n):
    """
    è®¡ç®—æ¯ä¸ªæ—¶é—´æˆ³ä¸Šçš„å€¼ä¸ºå½“å‰æ—¶é—´æˆ³æ•°æ®é™¤ä»¥å‰ä¸€å¤©ç›¸åŒæ—¶é—´å‰åå…±ä¸‰åˆ†é’Ÿçš„å‡å€¼ã€‚

    å‚æ•°ï¼š
    df (pd.DataFrame): datetimeä¸ºindexçš„æ•°æ®æ¡†ã€‚

    è¿”å›ï¼š
    pd.DataFrame: è®¡ç®—åçš„æ•°æ®æ¡†ã€‚
    """
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("DataFrameçš„indexå¿…é¡»æ˜¯DatetimeIndexç±»å‹")
    
    # è·å–å‰ä¸€å¤©ç›¸åŒæ—¶é—´å‰åå…±ä¸‰åˆ†é’Ÿçš„æ•°æ®
    prev_day = df.shift(n, freq='D')
    offsets = [-1, 0, 1]
    
    # è®¡ç®—å‰ä¸€å¤©ç›¸åŒæ—¶é—´å‰åå…±ä¸‰åˆ†é’Ÿçš„å‡å€¼
    prev_mean = prev_day.copy()
    prev_mean_values = []
    for offset in offsets:
        prev_mean_values.append(prev_day.shift(offset))
    prev_mean = sum(prev_mean_values) / len(prev_mean_values)
    
    # è®¡ç®—æ¯”å€¼
    result = df / prev_mean
    result = result.reindex(df.index)
    
    return result


def zscore(df, period_str):
    """
    è®¡ç®—æ¯ä¸ªæ—¶é—´æˆ³ä¸Šçš„å€¼ä¸º (å½“å‰å€¼ - è¿‡å»ä¸€æ®µæ—¶é—´çš„å‡å€¼) / è¿‡å»ä¸€æ®µæ—¶é—´çš„æ ‡å‡†å·®ã€‚

    å‚æ•°ï¼š
    df (pd.DataFrame): datetimeä¸ºindexçš„æ•°æ®æ¡†ã€‚
    period_str (str): è¿‡å»æ—¶é—´æ®µçš„é•¿åº¦ï¼Œå¯ä»¥æ˜¯å°æ—¶ï¼ˆå¦‚'4h'ï¼‰æˆ–å¤©ï¼ˆå¦‚'3d'ï¼‰ã€‚

    è¿”å›ï¼š
    pd.DataFrame: è®¡ç®—åçš„æ•°æ®æ¡†ã€‚
    """
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("DataFrameçš„indexå¿…é¡»æ˜¯DatetimeIndexç±»å‹")
    
    mean = df.rolling(window=period_str, min_periods=1).mean()
    std = df.rolling(window=period_str, min_periods=1).std()
    result = (df - mean) / std

    return result


def zscore_fxwd(df, period_str, freq='1min'):
    """
    è®¡ç®—æ¯ä¸ªæ—¶é—´æˆ³ä¸Šçš„å€¼ä¸º (å½“å‰å€¼ - è¿‡å»ä¸€æ®µæ—¶é—´çš„å‡å€¼) / è¿‡å»ä¸€æ®µæ—¶é—´çš„æ ‡å‡†å·®ã€‚
    å½“æ ‡å‡†å·®ä¸º 0 æ—¶ï¼Œè¿”å› NaNã€‚

    å‚æ•°ï¼š
    df (pd.DataFrame): datetime ä¸º index çš„æ•°æ®æ¡†ã€‚
    period_str (str): è¿‡å»æ—¶é—´æ®µçš„é•¿åº¦ï¼Œå¦‚ "4h"ã€"3d2h30min" ç­‰ã€‚
    freq (str): æ•°æ®çš„æ—¶é—´é—´éš”ï¼Œå¦‚ "1min"ã€"5min"ã€"10s"ã€‚

    è¿”å›ï¼š
    pd.DataFrame: è®¡ç®—åçš„æ•°æ®æ¡†ã€‚
    """
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("DataFrameçš„indexå¿…é¡»æ˜¯DatetimeIndexç±»å‹")
    
    # è®¡ç®—çª—å£å¤§å°
    window_size = get_num_of_bars(period_str, freq)

    if window_size < 1:
        raise ValueError("è®¡ç®—çš„çª—å£å¤§å°å°äº 1ï¼Œæ£€æŸ¥ period_str å’Œ freq æ˜¯å¦åŒ¹é…")

    mean = df.rolling(window=window_size, min_periods=1).mean()
    std = df.rolling(window=window_size, min_periods=1).std()
    
    # é˜²æ­¢é™¤ä»¥é›¶ï¼šå°†æ ‡å‡†å·®ä¸º0çš„åœ°æ–¹æ›¿æ¢ä¸ºNaN
    std_safe = std.replace(0, np.nan)
    
    result = (df - mean) / std_safe

    return result


def zsc(df, period_str, freq='1min'):
    """
    è®¡ç®—æ¯ä¸ªæ—¶é—´æˆ³ä¸Šçš„å€¼ä¸º (å½“å‰å€¼ - è¿‡å»ä¸€æ®µæ—¶é—´çš„å‡å€¼) / è¿‡å»ä¸€æ®µæ—¶é—´çš„æ ‡å‡†å·®ã€‚
    å½“æ ‡å‡†å·®ä¸º 0 æ—¶ï¼Œè¿”å› NaNã€‚

    å‚æ•°ï¼š
    df (pd.DataFrame): datetime ä¸º index çš„æ•°æ®æ¡†ã€‚
    period_str (str): è¿‡å»æ—¶é—´æ®µçš„é•¿åº¦ï¼Œå¦‚ "4h"ã€"3d2h30min" ç­‰ã€‚
    freq (str): æ•°æ®çš„æ—¶é—´é—´éš”ï¼Œå¦‚ "1min"ã€"5min"ã€"10s"ã€‚

    è¿”å›ï¼š
    pd.DataFrame: è®¡ç®—åçš„æ•°æ®æ¡†ã€‚
    """
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("DataFrameçš„indexå¿…é¡»æ˜¯DatetimeIndexç±»å‹")
    
    # è®¡ç®—çª—å£å¤§å°
    window_size = get_num_of_bars(period_str, freq)

    if window_size < 1:
        raise ValueError("è®¡ç®—çš„çª—å£å¤§å°å°äº 1ï¼Œæ£€æŸ¥ period_str å’Œ freq æ˜¯å¦åŒ¹é…")

    mean = df.rolling(window=window_size, min_periods=1).mean()
    std = df.rolling(window=window_size, min_periods=1).std()
    
    # é˜²æ­¢é™¤ä»¥é›¶ï¼šå°†æ ‡å‡†å·®ä¸º0çš„åœ°æ–¹æ›¿æ¢ä¸ºNaN
    std_safe = std.replace(0, np.nan)
    
    result = (df - mean) / std_safe

    return result


# %%
# =============================================================================
# def slope(df: pd.DataFrame, window: int | str) -> pd.DataFrame:
#     """
#     å¯¹ DataFrame ä¸­æ¯åˆ—è®¡ç®—æ»‘åŠ¨çª—å£æ–œç‡ï¼ˆçº¿æ€§æ‹Ÿåˆçš„æ–œç‡ï¼‰ï¼Œæ”¯æŒæ—¶é—´çª—å£ã€‚
#     
#     Args:
#         df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼ˆæ”¯æŒå¤šåˆ—ï¼‰ã€‚
#         window (int | str): æ»‘åŠ¨çª—å£å¤§å°ï¼Œå¯ä»¥æ˜¯æ•´æ•°æˆ–å­—ç¬¦ä¸²æ—¶é—´çª—å£ï¼ˆå¦‚ '5min'ï¼‰ã€‚
#         
#     Returns:
#         pd.DataFrame: æ¯åˆ—çš„æ»šåŠ¨çª—å£æ–œç‡ï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
#     """
#     def compute_slope(y):
#         # åŠ¨æ€ç”Ÿæˆ x åºåˆ—
#         n = len(y)
#         if n < 2:  # å¦‚æœçª—å£å¤§å°ä¸è¶³ï¼Œè¿”å› NaN
#             return np.nan
#         x = np.arange(n)
#         x_mean = x.mean()
#         x_squared_mean = (x**2).mean()
#         denominator = x_squared_mean - x_mean**2
#         
#         # è®¡ç®—æ–œç‡
#         y_mean = y.mean()
#         numerator = np.dot(y - y_mean, x - x_mean)
#         return numerator / denominator
# 
#     # åº”ç”¨æ»šåŠ¨çª—å£è®¡ç®—
#     slopes = df.rolling(window=window).apply(compute_slope, raw=False)
#     return slopes
# =============================================================================


@jit(nopython=True)
def compute_slope(y):
    """
    ä½¿ç”¨ Numba åŠ é€Ÿçš„æ–œç‡è®¡ç®—ã€‚
    
    Args:
        y (np.ndarray): çª—å£å†…çš„æ•°å€¼ã€‚
        
    Returns:
        float: è®¡ç®—å¾—åˆ°çš„æ–œç‡å€¼ã€‚
    """
    n = len(y)
    if n < 2:  # å¦‚æœçª—å£å¤§å°ä¸è¶³ï¼Œè¿”å› NaN
        return np.nan
    
    x = np.arange(n)
    x_mean = x.mean()
    y_mean = y.mean()
    x_squared_mean = (x**2).mean()
    denominator = x_squared_mean - x_mean**2
    numerator = np.dot(y - y_mean, x - x_mean)
    return numerator / denominator


def slope(df: pd.DataFrame, window: int | str) -> pd.DataFrame:
    """
    å¯¹ DataFrame ä¸­æ¯åˆ—è®¡ç®—æ»‘åŠ¨çª—å£æ–œç‡ï¼ˆçº¿æ€§æ‹Ÿåˆçš„æ–œç‡ï¼‰ï¼Œæ”¯æŒæ—¶é—´çª—å£ï¼Œå¹¶ä½¿ç”¨ Numba åŠ é€Ÿã€‚
    
    Args:
        df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼ˆæ”¯æŒå¤šåˆ—ï¼‰ã€‚
        window (int | str): æ»‘åŠ¨çª—å£å¤§å°ï¼Œå¯ä»¥æ˜¯æ•´æ•°æˆ–å­—ç¬¦ä¸²æ—¶é—´çª—å£ï¼ˆå¦‚ '5min'ï¼‰ã€‚
        
    Returns:
        pd.DataFrame: æ¯åˆ—çš„æ»šåŠ¨çª—å£æ–œç‡ï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    # åº”ç”¨æ»šåŠ¨çª—å£è®¡ç®—
    slopes = df.rolling(window=window, min_periods=1).apply(compute_slope, raw=True)
    return slopes


# %% f
def lowFreqEnergyRatio(df: pd.DataFrame, window, cutoff_freq: float, sampling_interval: float = 1) -> pd.DataFrame:
    """
    å¯¹ DataFrame ä¸­æ¯åˆ—è®¡ç®—æ»šåŠ¨çª—å£çš„ä½é¢‘èƒ½é‡å æ¯”ã€‚
    
    Args:
        df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼ˆæ”¯æŒå¤šåˆ—ï¼‰ã€‚
        window_size (int): æ»šåŠ¨çª—å£çš„é•¿åº¦ï¼ˆæ•°æ®ç‚¹æ•°ï¼‰ã€‚
        cutoff_freq (float): æˆªæ­¢é¢‘ç‡ï¼Œä¿ç•™ä½äºè¯¥é¢‘ç‡çš„åˆ†é‡ï¼ˆå•ä½ï¼šcycles per minuteï¼‰ã€‚
        sampling_interval (float): é‡‡æ ·é—´éš”ï¼ˆå•ä½ï¼šåˆ†é’Ÿï¼Œé»˜è®¤1åˆ†é’Ÿï¼‰ã€‚
        
    Returns:
        pd.DataFrame: æ»šåŠ¨çª—å£çš„ä½é¢‘èƒ½é‡å æ¯”ï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    def compute_energy_ratio(window_data):
        # è®¡ç®—å‚…é‡Œå¶å˜æ¢
        fft_result = np.fft.fft(window_data)
        freqs = np.fft.fftfreq(len(window_data), d=sampling_interval)
        
        # è®¡ç®—æ€»èƒ½é‡å’Œä½é¢‘èƒ½é‡
        total_energy = np.sum(np.abs(fft_result)**2)
        low_freq_energy = np.sum(np.abs(fft_result[np.abs(freqs) <= cutoff_freq])**2)
        
        # è¿”å›ä½é¢‘èƒ½é‡å æ¯”
        return low_freq_energy / total_energy
    
    # å¯¹ DataFrame æ¯åˆ—åº”ç”¨æ»šåŠ¨è®¡ç®—
    result = df.rolling(window=window, min_periods=1).apply(compute_energy_ratio, raw=True)
    return result


def freq_to_minutes(cutoff_freq: float) -> str:
    """
    å°†æˆªæ­¢é¢‘ç‡ (cutoff_freq) è½¬æ¢ä¸ºå®é™…åˆ†é’Ÿæ•°ï¼Œè¿”å›æ ¼å¼ä¸º xxminã€‚
    
    Args:
        cutoff_freq (float): æˆªæ­¢é¢‘ç‡ï¼ˆå•ä½ï¼šå‘¨æœŸæ¯åˆ†é’Ÿï¼Œcycles per minuteï¼‰ã€‚
        
    Returns:
        str: å®é™…åˆ†é’Ÿæ•°çš„å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œæ ¼å¼ä¸º "xxmin"ã€‚
    """
    if cutoff_freq <= 0:
        raise ValueError("cutoff_freq must be a positive value.")
    
    # è®¡ç®—å¯¹åº”çš„åˆ†é’Ÿæ•°
    minutes = round(1 / cutoff_freq)
    
    # è¿”å›æ ¼å¼åŒ–å­—ç¬¦ä¸²
    return f"{minutes}min"


def lowFreqEnergyRatio_x_slope(data, window, cutoff_freq, sampling_interval=1):
    energy_ratio = lowFreqEnergyRatio(data, window, cutoff_freq, sampling_interval)
    slp = slope(data, freq_to_minutes(cutoff_freq))
    return energy_ratio * slp


def lowFreqEnergyRatio_x_slpsign(data, window, cutoff_freq, sampling_interval=1):
    energy_ratio = lowFreqEnergyRatio(data, window, cutoff_freq, sampling_interval)
    slp = slope(data, freq_to_minutes(cutoff_freq))
    slp_sign = slp.apply(np.sign)  # ä½¿ç”¨ numpy.sign å¯¹æ¯åˆ—è®¡ç®—ç¬¦å·
    return energy_ratio * slp_sign


def phaseTimesMagnitude(df: pd.DataFrame, window, cutoff_freq: float, sampling_interval: float = 1) -> pd.DataFrame:
    """
    å¯¹ DataFrame ä¸­æ¯åˆ—è®¡ç®—æ»šåŠ¨çª—å£çš„ä½é¢‘ç›¸ä½ * å¹…å€¼ç»“æœã€‚
    
    Args:
        df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼ˆæ”¯æŒå¤šåˆ—ï¼‰ã€‚
        window (int | str): æ»šåŠ¨çª—å£çš„é•¿åº¦ï¼ˆæ•°æ®ç‚¹æ•°æˆ–æ—¶é—´çª—å£ï¼‰ã€‚
        cutoff_freq (float): æˆªæ­¢é¢‘ç‡ï¼Œä»…ä¿ç•™ä½äºè¯¥é¢‘ç‡çš„åˆ†é‡ã€‚
        sampling_interval (float): é‡‡æ ·é—´éš”ï¼ˆå•ä½ï¼šåˆ†é’Ÿï¼Œé»˜è®¤ 1 åˆ†é’Ÿï¼‰ã€‚
        
    Returns:
        pd.DataFrame: æ¯åˆ—çš„æ»šåŠ¨çª—å£ä½é¢‘ç›¸ä½ * å¹…å€¼ç»“æœçš„ç´¯åŠ å€¼ï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    def compute_phase_times_magnitude(window_data):
        # å¦‚æœçª—å£æ•°æ®ä¸è¶³ï¼Œè¿”å› NaN
        if len(window_data) < 2:
            return np.nan
        
        # è®¡ç®—å‚…é‡Œå¶å˜æ¢
        fft_result = np.fft.fft(window_data)
        freqs = np.fft.fftfreq(len(window_data), d=sampling_interval)
        
        # ç­›é€‰ä½é¢‘åˆ†é‡
        low_freq_mask = np.abs(freqs) <= cutoff_freq
        fft_result_low_freq = fft_result[low_freq_mask]
        
        # è®¡ç®—å¹…å€¼å’Œç›¸ä½
        magnitudes = np.abs(fft_result_low_freq)
        phases = np.angle(fft_result_low_freq)
        
        # ç›¸ä½ * å¹…å€¼
        phase_magnitude = phases * magnitudes
        
        # è¿”å›ç»“æœçš„ç´¯åŠ å€¼
        return np.sum(phase_magnitude)
    
    # å¯¹ DataFrame æ¯åˆ—åº”ç”¨æ»šåŠ¨è®¡ç®—
    result = df.rolling(window=window, min_periods=1).apply(compute_phase_times_magnitude, raw=True)
    return result


# %%
def mean(df: pd.DataFrame, window: int) -> pd.DataFrame:
    """
    è®¡ç®—æ»‘åŠ¨çª—å£å†…çš„å‡å€¼ã€‚

    Args:
        df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼ˆæ”¯æŒå¤šåˆ—ï¼‰ã€‚
        window (int): æ»‘åŠ¨çª—å£çš„å¤§å°ã€‚

    Returns:
        pd.DataFrame: æ»‘åŠ¨å‡å€¼ç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    return df.rolling(window, min_periods=1).mean()


def std(df: pd.DataFrame, window: int) -> pd.DataFrame:
    """
    è®¡ç®—æ»‘åŠ¨çª—å£å†…çš„æ ‡å‡†å·®ã€‚

    Args:
        df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼ˆæ”¯æŒå¤šåˆ—ï¼‰ã€‚
        window (int): æ»‘åŠ¨çª—å£çš„å¤§å°ã€‚

    Returns:
        pd.DataFrame: æ»‘åŠ¨æ ‡å‡†å·®ç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    return df.rolling(window, min_periods=1).std()


def skew(df: pd.DataFrame, window: int) -> pd.DataFrame:
    """
    è®¡ç®—æ»‘åŠ¨çª—å£å†…çš„ååº¦ã€‚

    Args:
        df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼ˆæ”¯æŒå¤šåˆ—ï¼‰ã€‚
        window (int): æ»‘åŠ¨çª—å£çš„å¤§å°ã€‚

    Returns:
        pd.DataFrame: æ»‘åŠ¨ååº¦ç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    return df.rolling(window, min_periods=1).skew()


def kurt(df: pd.DataFrame, window: int) -> pd.DataFrame:
    """
    è®¡ç®—æ»‘åŠ¨çª—å£å†…çš„å³°åº¦ã€‚

    Args:
        df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼ˆæ”¯æŒå¤šåˆ—ï¼‰ã€‚
        window (int): æ»‘åŠ¨çª—å£çš„å¤§å°ã€‚

    Returns:
        pd.DataFrame: æ»‘åŠ¨å³°åº¦ç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    return df.rolling(window, min_periods=1).kurt()


def rmin(df: pd.DataFrame, window: int) -> pd.DataFrame:
    """
    è®¡ç®—æ»‘åŠ¨çª—å£å†…çš„æœ€å°å€¼ã€‚

    Args:
        df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼ˆæ”¯æŒå¤šåˆ—ï¼‰ã€‚
        window (int): æ»‘åŠ¨çª—å£çš„å¤§å°ã€‚

    Returns:
        pd.DataFrame: æ»‘åŠ¨æœ€å°å€¼ç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    return df.rolling(window, min_periods=1).min()


def rmax(df: pd.DataFrame, window: int) -> pd.DataFrame:
    """
    è®¡ç®—æ»‘åŠ¨çª—å£å†…çš„æœ€å¤§å€¼ã€‚

    Args:
        df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼ˆæ”¯æŒå¤šåˆ—ï¼‰ã€‚
        window (int): æ»‘åŠ¨çª—å£çš„å¤§å°ã€‚

    Returns:
        pd.DataFrame: æ»‘åŠ¨æœ€å¤§å€¼ç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    return df.rolling(window, min_periods=1).max()


def iqr(df: pd.DataFrame, window: int) -> pd.DataFrame:
    """
    è®¡ç®—æ»‘åŠ¨çª—å£å†…çš„å››åˆ†ä½è·ï¼ˆ75åˆ†ä½æ•° - 25åˆ†ä½æ•°ï¼‰ã€‚
    
    Args:
        df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼ˆæ”¯æŒå¤šåˆ—ï¼‰ã€‚
        window (int): æ»‘åŠ¨çª—å£çš„å¤§å°ã€‚
        
    Returns:
        pd.DataFrame: æ»‘åŠ¨çª—å£å†…å››åˆ†ä½è·çš„ç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    q75 = df.rolling(window, min_periods=1).quantile(0.75)
    q25 = df.rolling(window, min_periods=1).quantile(0.25)
    return q75 - q25


def ewma(df: pd.DataFrame, span: int) -> pd.DataFrame:
    """
    è®¡ç®—è¿ç»­çš„æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡(EWMA)ï¼Œå…è®¸è·¨æ—¥è®¡ç®—ï¼Œä¸ä¼šåœ¨æ—¥æœŸè¾¹ç•Œé‡ç½®ã€‚
    
    Args:
        df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼ˆæ”¯æŒå¤šåˆ—ï¼‰ï¼Œindexä¸ºæ—¶é—´æˆ³ã€‚
        span (int): æŒ‡æ•°åŠ æƒçš„å‘¨æœŸæ•°ï¼Œç±»ä¼¼äºåŠè¡°æœŸã€‚
        
    Returns:
        pd.DataFrame: è¿ç»­æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡ç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    # ç›´æ¥å¯¹æ•´ä¸ªæ—¶é—´åºåˆ—åº”ç”¨ewmæ–¹æ³•ï¼Œä¸æŒ‰æ—¥æœŸåˆ†ç»„
    result = df.ewm(span=span, min_periods=1, adjust=True).mean()
    
    return result


# %% gpt - trend
def rsi(df: pd.DataFrame, period: str | int) -> pd.DataFrame: # relativeStrengthIndex
    """
    è®¡ç®—ç›¸å¯¹å¼ºå¼±æŒ‡æ•° (RSI)ã€‚
    
    å‚æ•°ï¼š
    df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼Œdatetime ä¸º indexã€‚
    period (int): è®¡ç®— RSI çš„æ—¶é—´æ­¥é•¿ã€‚
    
    è¿”å›ï¼š
    pd.DataFrame: æ¯åˆ—çš„ RSI å€¼ã€‚
    """
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("DataFrameçš„indexå¿…é¡»æ˜¯DatetimeIndexç±»å‹")
    
    delta = df.diff(1)
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    return rsi


def trendContinuation(df: pd.DataFrame, window: str | int) -> pd.DataFrame:
    """
    è®¡ç®—å› å­åœ¨æ»‘åŠ¨çª—å£å†…çš„è¶‹åŠ¿æ–¹å‘å»¶ç»­ç‡ï¼ˆåŒ…æ‹¬æ–¹å‘ä¿¡æ¯ï¼‰ã€‚
    
    å‚æ•°ï¼š
    df (pd.DataFrame): datetimeä¸ºindexçš„æ•°æ®æ¡†ã€‚
    window (int): æ»‘åŠ¨çª—å£å¤§å°ï¼ˆæ•°æ®ç‚¹æ•°ï¼‰ã€‚
    
    è¿”å›ï¼š
    pd.DataFrame: æ¯åˆ—çš„è¶‹åŠ¿æ–¹å‘å»¶ç»­ç‡ï¼ˆå¸¦æ–¹å‘ï¼ŒèŒƒå›´ä¸º-1åˆ°1ï¼‰ã€‚
    """
    def continuation(series):
        # å¦‚æœçª—å£æ•°æ®ä¸è¶³ï¼Œè¿”å› NaN
        if len(series) < 2:
            return np.nan
        diff = series.diff().dropna()
        if len(diff) < 2:
            return np.nan
        direction = np.sign(diff)
        continuation_rate = (direction == direction.iloc[0]).mean()
        return continuation_rate * direction.iloc[0]
    
    result = df.rolling(window=window, min_periods=1).apply(continuation, raw=False)
    return result


def trendReversalRate(df: pd.DataFrame, window: str | int) -> pd.DataFrame:
    """
    è®¡ç®—å› å­åœ¨æ»‘åŠ¨çª—å£å†…çš„è¶‹åŠ¿åè½¬ç‡ï¼ˆå¸¦æ–¹å‘ä¿¡æ¯ï¼‰ã€‚
    
    å‚æ•°ï¼š
    df (pd.DataFrame): datetimeä¸ºindexçš„æ•°æ®æ¡†ã€‚
    window (int): æ»‘åŠ¨çª—å£å¤§å°ï¼ˆæ•°æ®ç‚¹æ•°ï¼‰ã€‚
    
    è¿”å›ï¼š
    pd.DataFrame: æ¯åˆ—çš„è¶‹åŠ¿åè½¬ç‡ï¼ˆèŒƒå›´ä¸º -1 åˆ° 1ï¼‰ã€‚
    """
    def reversal(series):
        # å¦‚æœçª—å£æ•°æ®ä¸è¶³ï¼Œè¿”å› NaN
        if len(series) < 2:
            return np.nan
        diff = series.diff().dropna()
        if len(diff) < 2:
            return np.nan
        direction = np.sign(diff)
        reversals = (direction != direction.shift(1)).sum()
        total_changes = len(direction) - 1
        reversal_rate = reversals / total_changes if total_changes > 0 else 0
        return -reversal_rate if direction.iloc[-1] < 0 else reversal_rate
    
    result = df.rolling(window=window, min_periods=1).apply(reversal, raw=False)
    return result


def meanTrendDirectionConsistency(df: pd.DataFrame, window: str | int) -> pd.DataFrame:
    """
    è®¡ç®—æ»‘åŠ¨çª—å£å†…çš„å¹³å‡è¶‹åŠ¿æ–¹å‘ä¸€è‡´æ€§ã€‚
    
    å‚æ•°ï¼š
    df (pd.DataFrame): datetimeä¸ºindexçš„æ•°æ®æ¡†ã€‚
    window (int): æ»‘åŠ¨çª—å£å¤§å°ï¼ˆæ•°æ®ç‚¹æ•°ï¼‰ã€‚
    
    è¿”å›ï¼š
    pd.DataFrame: æ¯åˆ—çš„å¹³å‡è¶‹åŠ¿æ–¹å‘ä¸€è‡´æ€§ï¼ˆèŒƒå›´ -1 åˆ° 1ï¼‰ã€‚
    """
    def mean_consistency(series):
        # å¦‚æœçª—å£æ•°æ®ä¸è¶³ï¼Œè¿”å› NaN
        if len(series) < 2:
            return np.nan
        diff = series.diff().dropna()
        if len(diff) < 2:
            return np.nan
        direction = np.sign(diff)
        return direction.mean()
    
    result = df.rolling(window=window, min_periods=1).apply(mean_consistency, raw=False)
    return result


def trendDirectionEntropy(df: pd.DataFrame, window: str | int) -> pd.DataFrame:
    """
    è®¡ç®—æ»‘åŠ¨çª—å£å†…å› å­è¶‹åŠ¿æ–¹å‘çš„ç†µå€¼ï¼Œè¡¡é‡æ–¹å‘å˜åŒ–çš„éšæœºæ€§ã€‚
    
    å‚æ•°ï¼š
    df (pd.DataFrame): datetimeä¸ºindexçš„æ•°æ®æ¡†ã€‚
    window (int): æ»‘åŠ¨çª—å£å¤§å°ï¼ˆæ•°æ®ç‚¹æ•°ï¼‰ã€‚
    
    è¿”å›ï¼š
    pd.DataFrame: æ¯åˆ—è¶‹åŠ¿æ–¹å‘çš„ç†µå€¼ï¼ˆèŒƒå›´ä¸º 0 åˆ° 1ï¼‰ã€‚
    """
    def entropy(series):
        # å¦‚æœçª—å£æ•°æ®ä¸è¶³ï¼Œè¿”å› NaN
        if len(series) < 2:
            return np.nan
        diff = series.diff().dropna()
        if len(diff) < 2:
            return np.nan
        direction = np.sign(diff)
        counts = direction.value_counts(normalize=True)
        return -np.sum(counts * np.log2(counts + 1e-9))
    
    result = df.rolling(window=window, min_periods=1).apply(entropy, raw=False)
    return result


def trendStrengthRatio(df: pd.DataFrame, window: str | int) -> pd.DataFrame:
    """
    è®¡ç®—æ»‘åŠ¨çª—å£å†…å› å­è¶‹åŠ¿çš„å¼ºåº¦æ¯”ç‡ï¼ˆè¶‹åŠ¿æŒ¯å¹…ä¸å™ªå£°çš„æ¯”å€¼ï¼‰ã€‚
    
    å‚æ•°ï¼š
    df (pd.DataFrame): datetimeä¸ºindexçš„æ•°æ®æ¡†ã€‚
    window (int): æ»‘åŠ¨çª—å£å¤§å°ï¼ˆæ•°æ®ç‚¹æ•°ï¼‰ã€‚
    
    è¿”å›ï¼š
    pd.DataFrame: æ¯åˆ—è¶‹åŠ¿å¼ºåº¦æ¯”ç‡ï¼ˆæ­£è´Ÿå€¼ï¼Œæ–¹å‘ä¸è¶‹åŠ¿ä¸€è‡´ï¼‰ã€‚
    """
    def strength_ratio(series):
        # å¦‚æœçª—å£æ•°æ®ä¸è¶³ï¼Œè¿”å› NaN
        if len(series) < 2:
            return np.nan
        diff = series.diff().dropna()
        if len(diff) < 2:
            return np.nan
        trend_amplitude = series.max() - series.min()
        noise = np.std(diff)
        return trend_amplitude / (noise + 1e-9) * np.sign(diff.mean())
    
    result = df.rolling(window=window, min_periods=1).apply(strength_ratio, raw=False)
    return result


# %% gpt - percentile
def relativePercentileChange(df: pd.DataFrame, short_window: int, long_window: int) -> pd.DataFrame:
    """
    è®¡ç®—å› å­åœ¨çŸ­æœŸè¶‹åŠ¿ä¸Šçš„ç›¸å¯¹ä½ç½®å˜åŒ–ç‡ï¼Œç›¸å¯¹äºé•¿æœŸçª—å£å†…çš„åˆ†å¸ƒã€‚
    
    å‚æ•°ï¼š
    df (pd.DataFrame): datetimeä¸ºindexçš„æ•°æ®æ¡†ã€‚
    short_window (int): çŸ­æœŸçª—å£å¤§å°ï¼Œç”¨äºè®¡ç®—å½“å‰è¶‹åŠ¿å€¼ã€‚
    long_window (int): é•¿æœŸçª—å£å¤§å°ï¼Œç”¨äºå®šä¹‰ç›¸å¯¹ä½ç½®çš„åˆ†å¸ƒã€‚
    
    è¿”å›ï¼š
    pd.DataFrame: æ¯åˆ—çš„ç›¸å¯¹ä½ç½®å˜åŒ–ç‡ï¼ˆç™¾åˆ†ä½å˜åŒ–ï¼‰ã€‚
    """
    def percentile_change(series):
        # å¦‚æœçª—å£æ•°æ®ä¸è¶³ï¼Œè¿”å› NaN
        if len(series) < 2:
            return np.nan
        short_value = series.iloc[-short_window:].mean()
        long_window_values = series.iloc[-long_window:]
        rank = (long_window_values < short_value).sum() / len(long_window_values)
        return rank
    
    # è®¡ç®—çŸ­æœŸç›¸å¯¹é•¿æœŸçš„ç™¾åˆ†ä½
    result = df.rolling(long_window, min_periods=1).apply(percentile_change, raw=False).diff()
    return result


def layeredPercentileTrend(df: pd.DataFrame, short_window: int, long_window: int) -> pd.DataFrame:
    """
    åˆ†å±‚è®¡ç®—å› å­åœ¨é•¿æœŸåˆ†å¸ƒä¸­çš„ç›¸å¯¹ç™¾åˆ†ä½ï¼Œä»¥åŠçŸ­æœŸè¶‹åŠ¿ã€‚
    
    å‚æ•°ï¼š
    df (pd.DataFrame): datetimeä¸ºindexçš„æ•°æ®æ¡†ã€‚
    short_window (int): çŸ­æœŸçª—å£å¤§å°ï¼Œç”¨äºè®¡ç®—è¶‹åŠ¿ã€‚
    long_window (int): é•¿æœŸçª—å£å¤§å°ï¼Œç”¨äºè®¡ç®—ç›¸å¯¹ä½ç½®ã€‚
    
    è¿”å›ï¼š
    pd.DataFrame: æ¯åˆ—çš„åˆ†å±‚ç™¾åˆ†ä½è¶‹åŠ¿ï¼ŒåŒ…å«æ–¹å‘ä¿¡æ¯ã€‚
    """
    def layered_trend(series):
        # å¦‚æœçª—å£æ•°æ®ä¸è¶³ï¼Œè¿”å› NaN
        if len(series) < 2:
            return np.nan
        short_value = series.iloc[-short_window:].mean()
        long_window_values = series.iloc[-long_window:]
        rank = (long_window_values < short_value).sum() / len(long_window_values)
        short_trend = series.diff(short_window).iloc[-1]
        return rank * np.sign(short_trend)
    
    result = df.rolling(long_window, min_periods=1).apply(layered_trend, raw=False)
    return result


def relativeExtremeTrend(df: pd.DataFrame, short_window: int, long_window: int) -> pd.DataFrame:
    """
    è®¡ç®—å› å­å€¼ç›¸å¯¹äºé•¿æœŸçª—å£çš„æå€¼ä½ç½®ï¼Œä»¥åŠçŸ­æœŸè¶‹åŠ¿ã€‚
    
    å‚æ•°ï¼š
    df (pd.DataFrame): datetimeä¸ºindexçš„æ•°æ®æ¡†ã€‚
    short_window (int): çŸ­æœŸçª—å£å¤§å°ï¼Œç”¨äºè®¡ç®—è¶‹åŠ¿ã€‚
    long_window (int): é•¿æœŸçª—å£å¤§å°ï¼Œç”¨äºè®¡ç®—ç›¸å¯¹æå€¼ã€‚
    
    è¿”å›ï¼š
    pd.DataFrame: æ¯åˆ—çš„æå€¼ç›¸å¯¹ä½ç½®ä¸çŸ­æœŸè¶‹åŠ¿çš„ç»“åˆå€¼ã€‚
    """
    def extreme_trend(series):
        # å¦‚æœçª—å£æ•°æ®ä¸è¶³ï¼Œè¿”å› NaN
        if len(series) < 2:
            return np.nan
        short_value = series.iloc[-short_window:].mean()
        long_max = series.iloc[-long_window:].max()
        long_min = series.iloc[-long_window:].min()
        relative_position = (short_value - long_min) / (long_max - long_min + 1e-9)
        short_trend = series.diff(short_window).iloc[-1]
        return relative_position * np.sign(short_trend)
    
    result = df.rolling(long_window, min_periods=1).apply(extreme_trend, raw=False)
    return result


def shortLongTrendInteraction(df: pd.DataFrame, short_window: int, long_window: int) -> pd.DataFrame:
    """
    è®¡ç®—çŸ­æœŸè¶‹åŠ¿å¼ºåº¦ä¸é•¿æœŸè¶‹åŠ¿å¼ºåº¦çš„äº¤äº’å…³ç³»ã€‚
    
    å‚æ•°ï¼š
    df (pd.DataFrame): datetimeä¸ºindexçš„æ•°æ®æ¡†ã€‚
    short_window (int): çŸ­æœŸçª—å£å¤§å°ï¼Œç”¨äºè®¡ç®—çŸ­æœŸè¶‹åŠ¿ã€‚
    long_window (int): é•¿æœŸçª—å£å¤§å°ï¼Œç”¨äºè®¡ç®—é•¿æœŸè¶‹åŠ¿ã€‚
    
    è¿”å›ï¼š
    pd.DataFrame: æ¯åˆ—çš„çŸ­é•¿æœŸè¶‹åŠ¿äº¤äº’å¼ºåº¦ã€‚
    """
    def interaction(series):
        # å¦‚æœçª—å£æ•°æ®ä¸è¶³ï¼Œè¿”å› NaN
        if len(series) < 2:
            return np.nan
        short_trend = series.diff(short_window).mean()
        long_trend = series.diff(long_window).mean()
        return short_trend * long_trend
    
    result = df.rolling(long_window, min_periods=1).apply(interaction, raw=False)
    return result


def percentileTrendAcceleration(df: pd.DataFrame, short_window: int, long_window: int) -> pd.DataFrame:
    """
    è®¡ç®—å› å­åœ¨é•¿æœŸåˆ†å¸ƒä¸­çš„åˆ†ä½ç‚¹å˜åŒ–åŠ é€Ÿåº¦ã€‚
    
    å‚æ•°ï¼š
    df (pd.DataFrame): datetimeä¸ºindexçš„æ•°æ®æ¡†ã€‚
    short_window (int): çŸ­æœŸçª—å£å¤§å°ï¼Œç”¨äºè®¡ç®—è¶‹åŠ¿åŠ é€Ÿåº¦ã€‚
    long_window (int): é•¿æœŸçª—å£å¤§å°ï¼Œç”¨äºè®¡ç®—åˆ†ä½ç‚¹åˆ†å¸ƒã€‚
    
    è¿”å›ï¼š
    pd.DataFrame: æ¯åˆ—çš„åˆ†ä½ç‚¹è¶‹åŠ¿åŠ é€Ÿåº¦ã€‚
    """
    def percentile_acceleration(series):
        # å¦‚æœçª—å£æ•°æ®ä¸è¶³ï¼Œè¿”å› NaN
        if len(series) < 2:
            return np.nan
        short_value = series.iloc[-short_window:].mean()
        long_window_values = series.iloc[-long_window:]
        rank = (long_window_values < short_value).sum() / len(long_window_values)
        rank_diff = rank - (long_window_values < series.iloc[-short_window-1:-1].mean()).sum() / len(long_window_values)
        return rank_diff
    
    result = df.rolling(long_window, min_periods=1).apply(percentile_acceleration, raw=False)
    return result


# %% gpt - ft
def lowFreqWithPosTrend(df: pd.DataFrame, fft_window: str | int, pos_window: str | int, 
                        freq_cutoff: float, sampling_interval: float) -> pd.DataFrame:
    """
    æå–çŸ­æœŸå‚…é‡Œå¶å˜æ¢çš„ä½é¢‘å¹…åº¦ï¼Œå¹¶æ ¹æ®å› å­å€¼åœ¨é•¿æœŸçª—å£å†…çš„ç›¸å¯¹ä½ç½®åˆ¤æ–­è¶‹åŠ¿æ–¹å‘ã€‚
    
    å‚æ•°ï¼š
    df (pd.DataFrame): datetimeä¸ºindexçš„æ•°æ®æ¡†ã€‚
    fft_window (str | int): ç”¨äºå‚…é‡Œå¶å˜æ¢çš„çŸ­æœŸçª—å£å¤§å°ã€‚
    pos_window (str | int): ç”¨äºè®¡ç®—é•¿æœŸç›¸å¯¹ä½ç½®çš„çª—å£å¤§å°ã€‚
    freq_cutoff (float): ä½é¢‘åˆ†é‡çš„æˆªæ­¢é¢‘ç‡ã€‚
    sampling_interval (float): é‡‡æ ·é—´éš”ã€‚
    
    è¿”å›ï¼š
    pd.DataFrame: æ¯åˆ—çš„çŸ­æœŸä½é¢‘å¹…åº¦ä¸åŸºäºé•¿æœŸç›¸å¯¹ä½ç½®çš„è¶‹åŠ¿æ–¹å‘äº¤äº’ç»“æœã€‚
    """
    def compute_low_freq_amplitude(series):
        # å¦‚æœçª—å£æ•°æ®ä¸è¶³ï¼Œè¿”å› NaN
        if len(series) < 2:
            return np.nan
        fft_result = np.fft.fft(series)
        freqs = np.fft.fftfreq(len(series), d=sampling_interval)
        low_freq_amplitude = np.sum(np.abs(fft_result[np.abs(freqs) <= freq_cutoff]))
        return low_freq_amplitude

    def compute_pos_trend(series):
        # å¦‚æœçª—å£æ•°æ®ä¸è¶³ï¼Œè¿”å› NaN
        if len(series) < 2:
            return np.nan
        rank = (series < series.iloc[-1]).sum() / len(series)
        return 1 if rank > 0.5 else -1

    low_freq_amplitude = df.rolling(window=fft_window, min_periods=1).apply(compute_low_freq_amplitude, raw=False)
    pos_trend = df.rolling(window=pos_window, min_periods=1).apply(compute_pos_trend, raw=False)

    return low_freq_amplitude * pos_trend


# %% gpt - intraday effect
def rollingRemoveIntradayEffect(df: pd.DataFrame, window: str = '30d', time_col: str = "time") -> pd.DataFrame:
    """
    æ»šåŠ¨å»é™¤å› å­ä¸­çš„æ—¥å†…æ•ˆåº”ï¼Œæ¯ä¸ªæ—¶é—´ç‚¹å›çœ‹çª—å£å†…çš„å‡å€¼ã€‚

    å‚æ•°ï¼š
        df (pd.DataFrame): åŒ…å«æ—¶é—´åºåˆ—çš„DataFrameï¼Œindexä¸ºDatetimeIndexã€‚
        window (int): å›çœ‹æ»šåŠ¨çª—å£å¤§å°ï¼ˆå¤©æ•°ï¼‰ã€‚
        time_col (str): æ¯å¤©çš„å…·ä½“æ—¶é—´ç‚¹åˆ—åï¼ˆå¦‚ '09:30'ï¼‰ã€‚

    è¿”å›ï¼š
        pd.DataFrame: å»é™¤æ»šåŠ¨çª—å£å†…æ—¥å†…æ•ˆåº”åçš„æ•°æ®ã€‚
    """
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("DataFrameçš„indexå¿…é¡»æ˜¯DatetimeIndexç±»å‹")
    
    # 2. æå–æ¯å¤©çš„æ—¶é—´ç‚¹ï¼Œå•ç‹¬å­˜å‚¨ï¼Œé¿å…æ±¡æŸ“æ•°æ®
    time_points = df.index.time
    
    # 3. æ»šåŠ¨è®¡ç®—æ—¥å†…å‡å€¼
    rolling_result = df.groupby(time_points, group_keys=False).apply(
        lambda x: x.rolling(window=window, min_periods=1).mean()
    )
    
    # 4. å»é™¤æ»šåŠ¨å‡å€¼çš„å½±å“
    result = df - rolling_result
    
    return result


def rollingMinuteQuantileScale(
    df: pd.DataFrame,
    window: str = "30d",
    min_periods: int = 1,
    quantile: float = 0.05
) -> pd.DataFrame:
    """
    æ¯åˆ†é’Ÿæ—¶é—´ç‚¹çš„æ»šåŠ¨çª—å£åˆ†ä½æ•°å½’ä¸€åŒ–ã€‚
    
    å‚æ•°:
        df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼Œindex å¿…é¡»ä¸º DatetimeIndexã€‚
        window (str, optional): æ»šåŠ¨çª—å£å¤§å°ï¼Œæ”¯æŒ Pandas æ—¶é—´çª—å£ï¼ˆå¦‚ "30d" è¡¨ç¤º30å¤©ï¼‰ã€‚é»˜è®¤å€¼ä¸º "30d"ã€‚
        min_periods (int, optional): çª—å£ä¸­è¦æ±‚çš„æœ€å°‘è§‚å¯Ÿæ•°ï¼Œé»˜è®¤å€¼ä¸º 10ã€‚
        quantile (float, optional): ç”¨äºå½’ä¸€åŒ–çš„åˆ†ä½æ•°ï¼Œé»˜è®¤å€¼ä¸º 0.05ã€‚
        
    è¿”å›:
        pd.DataFrame: å½’ä¸€åŒ–åçš„æ•°æ®ã€‚
    """
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("DataFrame çš„ index å¿…é¡»æ˜¯ DatetimeIndex ç±»å‹")
    
    # å®šä¹‰åˆ†ä½æ•°
    lower_quantile = quantile
    upper_quantile = 1 - quantile

    # æå–æ¯åˆ†é’Ÿçš„æ—¶é—´ç‚¹
    minutes = df.index.time  # ä½¿ç”¨ç´¢å¼•æ—¶é—´æå–åˆ†é’Ÿä¿¡æ¯ï¼Œè€Œä¸æ·»åŠ åˆ—

    # åˆå§‹åŒ–å­˜å‚¨ç»“æœ
    result = pd.DataFrame(index=df.index, columns=df.columns)

    # æŒ‰åˆ†é’Ÿåˆ†ç»„
    unique_minutes = np.unique(minutes)
    for minute in unique_minutes:
        # æ‰¾åˆ°å½“å‰åˆ†é’Ÿå¯¹åº”çš„ç´¢å¼•
        mask = minutes == minute
        group = df[mask]

        # å¯¹æ¯ç»„æŒ‰æ»šåŠ¨çª—å£è®¡ç®—åˆ†ä½æ•°
        rolling_lower = group.rolling(window=window, min_periods=min_periods).quantile(lower_quantile)
        rolling_upper = group.rolling(window=window, min_periods=min_periods).quantile(upper_quantile)

        # å½’ä¸€åŒ–ï¼šåŸºäºåˆ†ä½æ•°è¿›è¡Œç¼©æ”¾
        scaled = (group - rolling_lower) / (rolling_upper - rolling_lower).replace(0, np.nan)
        
        # è£å‰ªç»“æœåœ¨ 0 å’Œ 1 ä¹‹é—´
        result.loc[group.index] = scaled.clip(lower=0, upper=1)

    return result


# =============================================================================
# def rollingAggMinuteMinMaxScale(
#     df: pd.DataFrame,
#     window: str = "30d",
#     min_periods: int = 1,
#     quantile: float = 0.05,
#     interval: int = 5
# ) -> pd.DataFrame:
#     """
#     æ¯åˆ†é’Ÿæ—¶é—´ç‚¹çš„æ»šåŠ¨çª—å£åˆ†ä½æ•°å½’ä¸€åŒ–ï¼ŒåŒæ—¶èšåˆåˆ°æ•´ interval åˆ†é’Ÿã€‚
# 
#     å‚æ•°:
#         df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼Œindex å¿…é¡»ä¸º DatetimeIndexã€‚
#         window (str, optional): æ»šåŠ¨çª—å£å¤§å°ï¼Œæ”¯æŒ Pandas æ—¶é—´çª—å£ï¼ˆå¦‚ "30d" è¡¨ç¤º30å¤©ï¼‰ã€‚é»˜è®¤å€¼ä¸º "30d"ã€‚
#         min_periods (int, optional): çª—å£ä¸­è¦æ±‚çš„æœ€å°‘è§‚å¯Ÿæ•°ï¼Œé»˜è®¤å€¼ä¸º 1ã€‚
#         quantile (float, optional): ç”¨äºå½’ä¸€åŒ–çš„åˆ†ä½æ•°ï¼Œé»˜è®¤å€¼ä¸º 0.05ã€‚
#         interval (int, optional): æ—¶é—´åˆ†ç»„çš„é—´éš”ï¼ˆä»¥åˆ†é’Ÿä¸ºå•ä½ï¼‰ï¼Œé»˜è®¤å€¼ä¸º 5ã€‚
# 
#     è¿”å›:
#         pd.DataFrame: å½’ä¸€åŒ–åçš„æ•°æ®ã€‚
#     """
#     if not isinstance(df.index, pd.DatetimeIndex):
#         raise ValueError("DataFrame çš„ index å¿…é¡»æ˜¯ DatetimeIndex ç±»å‹")
# 
#     # æå–åˆ†é’Ÿå¹¶åˆ†ç»„åˆ°æœ€è¿‘çš„æ•´ interval åˆ†é’Ÿ
#     grouped_minutes = (df.index.minute // interval) * interval
#     group_labels = df.index.hour * 60 + grouped_minutes
# 
#     # åˆå§‹åŒ–å­˜å‚¨ç»“æœ
#     result = pd.DataFrame(index=df.index, columns=df.columns)
# 
#     for group_id in np.unique(group_labels):
#         # æå–å½“å‰ç»„
#         group_mask = group_labels == group_id
#         group = df[group_mask]
# 
#         # å¯¹æ¯ç»„æŒ‰æ»šåŠ¨çª—å£è®¡ç®—åˆ†ä½æ•°
#         rolling_lower = group.rolling(window=window, min_periods=min_periods).quantile(quantile)
#         rolling_upper = group.rolling(window=window, min_periods=min_periods).quantile(1 - quantile)
# 
#         # å½’ä¸€åŒ–ï¼šåŸºäºåˆ†ä½æ•°è¿›è¡Œç¼©æ”¾
#         scaled = (group - rolling_lower) / (rolling_upper - rolling_lower).replace(0, np.nan)
# 
#         # è£å‰ªç»“æœåœ¨ 0 å’Œ 1 ä¹‹é—´
#         result.loc[group.index] = scaled.clip(lower=0, upper=1)
# 
#     return result
# 
# 
# def rollingAggMinutePercentile(
#     df: pd.DataFrame,
#     window: str = "30d",
#     min_periods: int = 1,
#     interval: int = 5
# ) -> pd.DataFrame:
#     """
#     æ¯åˆ†é’Ÿæ—¶é—´ç‚¹çš„æ»šåŠ¨çª—å£ç™¾åˆ†ä½è®¡ç®—ï¼Œå¹¶èšåˆåˆ°æ•´ interval åˆ†é’Ÿã€‚
# 
#     å‚æ•°:
#         df (pd.DataFrame): æ—¶é—´åºåˆ—æ•°æ®ï¼Œindex å¿…é¡»ä¸º DatetimeIndexã€‚
#         window (str, optional): æ»šåŠ¨çª—å£å¤§å°ï¼Œæ”¯æŒ Pandas æ—¶é—´çª—å£ï¼ˆå¦‚ "30d" è¡¨ç¤º30å¤©ï¼‰ã€‚é»˜è®¤å€¼ä¸º "30d"ã€‚
#         min_periods (int, optional): çª—å£ä¸­è¦æ±‚çš„æœ€å°‘è§‚å¯Ÿæ•°ï¼Œé»˜è®¤å€¼ä¸º 1ã€‚
#         interval (int, optional): æ—¶é—´åˆ†ç»„çš„é—´éš”ï¼ˆä»¥åˆ†é’Ÿä¸ºå•ä½ï¼‰ï¼Œé»˜è®¤å€¼ä¸º 5ã€‚
# 
#     è¿”å›:
#         pd.DataFrame: ç™¾åˆ†ä½å½’ä¸€åŒ–åçš„æ•°æ®ã€‚
#     """
#     if not isinstance(df.index, pd.DatetimeIndex):
#         raise ValueError("DataFrame çš„ index å¿…é¡»æ˜¯ DatetimeIndex ç±»å‹")
# 
#     # æå–åˆ†é’Ÿå¹¶åˆ†ç»„åˆ°æœ€è¿‘çš„æ•´ interval åˆ†é’Ÿ
#     grouped_minutes = (df.index.minute // interval) * interval
#     group_labels = df.index.hour * 60 + grouped_minutes
# 
#     # åˆå§‹åŒ–å­˜å‚¨ç»“æœ
#     result = pd.DataFrame(index=df.index, columns=df.columns)
# 
#     for group_id in np.unique(group_labels):
#         # æå–å½“å‰ç»„
#         group_mask = group_labels == group_id
#         group = df[group_mask]
# 
#         # å¯¹æ¯ç»„æŒ‰æ»šåŠ¨çª—å£è®¡ç®—ç™¾åˆ†ä½æ•°
#         rolling_percentile = group.rolling(window=window, min_periods=min_periods).apply(
#             lambda x: 100 * (x.iloc[-1] <= x).sum() / len(x), raw=False
#         )
# 
#         # å­˜å‚¨ç»“æœ
#         result.loc[group.index] = rolling_percentile
# 
#     return result
# =============================================================================


def rollingAggMinuteMinMaxScale(
    data,
    window: str = "30d",
    min_periods: int = 1,
    quantile: float = 0.05,
    interval: int = 5
):
    """
    æ¯åˆ†é’Ÿæ—¶é—´ç‚¹çš„æ»šåŠ¨çª—å£åˆ†ä½æ•°å½’ä¸€åŒ–ï¼ŒåŒæ—¶èšåˆåˆ°æ•´ interval åˆ†é’Ÿã€‚
    å‚æ•°:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯ DataFrame æˆ– Seriesï¼Œindex å¿…é¡»ä¸º DatetimeIndexã€‚
        window (str, optional): æ»šåŠ¨çª—å£å¤§å°ï¼Œæ”¯æŒ Pandas æ—¶é—´çª—å£ï¼ˆå¦‚ "30d" è¡¨ç¤º30å¤©ï¼‰ã€‚é»˜è®¤å€¼ä¸º "30d"ã€‚
        min_periods (int, optional): çª—å£ä¸­è¦æ±‚çš„æœ€å°‘è§‚å¯Ÿæ•°ï¼Œé»˜è®¤å€¼ä¸º 1ã€‚
        quantile (float, optional): ç”¨äºå½’ä¸€åŒ–çš„åˆ†ä½æ•°ï¼Œé»˜è®¤å€¼ä¸º 0.05ã€‚
        interval (int, optional): æ—¶é—´åˆ†ç»„çš„é—´éš”ï¼ˆä»¥åˆ†é’Ÿä¸ºå•ä½ï¼‰ï¼Œé»˜è®¤å€¼ä¸º 5ã€‚
    è¿”å›:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„å½’ä¸€åŒ–åçš„æ•°æ®ï¼ˆDataFrame æˆ– Seriesï¼‰ã€‚
    """
    # å°† Series è½¬æ¢ä¸º DataFrame è¿›è¡Œå¤„ç†
    is_series = isinstance(data, pd.Series)
    df = data.to_frame() if is_series else data.copy()
    
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("è¾“å…¥æ•°æ®çš„ index å¿…é¡»æ˜¯ DatetimeIndex ç±»å‹")
    
    # æå–åˆ†é’Ÿå¹¶åˆ†ç»„åˆ°æœ€è¿‘çš„æ•´ interval åˆ†é’Ÿ
    grouped_minutes = (df.index.minute // interval) * interval
    group_labels = df.index.hour * 60 + grouped_minutes
    
    # åˆå§‹åŒ–å­˜å‚¨ç»“æœ
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    for group_id in np.unique(group_labels):
        # æå–å½“å‰ç»„
        group_mask = group_labels == group_id
        group = df[group_mask]
        
        # å¯¹æ¯ç»„æŒ‰æ»šåŠ¨çª—å£è®¡ç®—åˆ†ä½æ•°
        rolling_lower = group.rolling(window=window, min_periods=min_periods).quantile(quantile)
        rolling_upper = group.rolling(window=window, min_periods=min_periods).quantile(1 - quantile)
        
        # å½’ä¸€åŒ–ï¼šåŸºäºåˆ†ä½æ•°è¿›è¡Œç¼©æ”¾
        scaled = (group - rolling_lower) / (rolling_upper - rolling_lower).replace(0, np.nan)
        
        # è£å‰ªç»“æœåœ¨ 0 å’Œ 1 ä¹‹é—´
        result.loc[group.index] = scaled.clip(lower=0, upper=1)
    
    # å¦‚æœè¾“å…¥æ˜¯ Seriesï¼Œåˆ™è¿”å› Series
    if is_series:
        return result.iloc[:, 0]
    return result


def aggMinmax(
    data,
    window: str = "30d",
    min_periods: int = 1,
    quantile: float = 0.05,
    interval: int = 5
):
    """
    æ¯åˆ†é’Ÿæ—¶é—´ç‚¹çš„æ»šåŠ¨çª—å£åˆ†ä½æ•°å½’ä¸€åŒ–ï¼ŒåŒæ—¶èšåˆåˆ°æ•´ interval åˆ†é’Ÿã€‚
    å‚æ•°:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯ DataFrame æˆ– Seriesï¼Œindex å¿…é¡»ä¸º DatetimeIndexã€‚
        window (str, optional): æ»šåŠ¨çª—å£å¤§å°ï¼Œæ”¯æŒ Pandas æ—¶é—´çª—å£ï¼ˆå¦‚ "30d" è¡¨ç¤º30å¤©ï¼‰ã€‚é»˜è®¤å€¼ä¸º "30d"ã€‚
        min_periods (int, optional): çª—å£ä¸­è¦æ±‚çš„æœ€å°‘è§‚å¯Ÿæ•°ï¼Œé»˜è®¤å€¼ä¸º 1ã€‚
        quantile (float, optional): ç”¨äºå½’ä¸€åŒ–çš„åˆ†ä½æ•°ï¼Œé»˜è®¤å€¼ä¸º 0.05ã€‚
        interval (int, optional): æ—¶é—´åˆ†ç»„çš„é—´éš”ï¼ˆä»¥åˆ†é’Ÿä¸ºå•ä½ï¼‰ï¼Œé»˜è®¤å€¼ä¸º 5ã€‚
    è¿”å›:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„å½’ä¸€åŒ–åçš„æ•°æ®ï¼ˆDataFrame æˆ– Seriesï¼‰ã€‚
    """
    # å°† Series è½¬æ¢ä¸º DataFrame è¿›è¡Œå¤„ç†
    is_series = isinstance(data, pd.Series)
    df = data.to_frame() if is_series else data.copy()
    
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("è¾“å…¥æ•°æ®çš„ index å¿…é¡»æ˜¯ DatetimeIndex ç±»å‹")
    
    # æå–åˆ†é’Ÿå¹¶åˆ†ç»„åˆ°æœ€è¿‘çš„æ•´ interval åˆ†é’Ÿ
    grouped_minutes = (df.index.minute // interval) * interval
    group_labels = df.index.hour * 60 + grouped_minutes
    
    # åˆå§‹åŒ–å­˜å‚¨ç»“æœ
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    for group_id in np.unique(group_labels):
        # æå–å½“å‰ç»„
        group_mask = group_labels == group_id
        group = df[group_mask]
        
        # å¯¹æ¯ç»„æŒ‰æ»šåŠ¨çª—å£è®¡ç®—åˆ†ä½æ•°
        rolling_lower = group.rolling(window=window, min_periods=min_periods).quantile(quantile)
        rolling_upper = group.rolling(window=window, min_periods=min_periods).quantile(1 - quantile)
        
        # å½’ä¸€åŒ–ï¼šåŸºäºåˆ†ä½æ•°è¿›è¡Œç¼©æ”¾
        scaled = (group - rolling_lower) / (rolling_upper - rolling_lower).replace(0, np.nan)
        
        # è£å‰ªç»“æœåœ¨ 0 å’Œ 1 ä¹‹é—´
        result.loc[group.index] = scaled.clip(lower=0, upper=1)
    
    # å¦‚æœè¾“å…¥æ˜¯ Seriesï¼Œåˆ™è¿”å› Series
    if is_series:
        return result.iloc[:, 0]
    return result


def rollingAggMinutePercentile(
    data,
    window: str = "30d",
    min_periods: int = 1,
    interval: int = 5
):
    """
    æ¯åˆ†é’Ÿæ—¶é—´ç‚¹çš„æ»šåŠ¨çª—å£ç™¾åˆ†ä½è®¡ç®—ï¼Œå¹¶èšåˆåˆ°æ•´ interval åˆ†é’Ÿã€‚
    å‚æ•°:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯ DataFrame æˆ– Seriesï¼Œindex å¿…é¡»ä¸º DatetimeIndexã€‚
        window (str, optional): æ»šåŠ¨çª—å£å¤§å°ï¼Œæ”¯æŒ Pandas æ—¶é—´çª—å£ï¼ˆå¦‚ "30d" è¡¨ç¤º30å¤©ï¼‰ã€‚é»˜è®¤å€¼ä¸º "30d"ã€‚
        min_periods (int, optional): çª—å£ä¸­è¦æ±‚çš„æœ€å°‘è§‚å¯Ÿæ•°ï¼Œé»˜è®¤å€¼ä¸º 1ã€‚
        interval (int, optional): æ—¶é—´åˆ†ç»„çš„é—´éš”ï¼ˆä»¥åˆ†é’Ÿä¸ºå•ä½ï¼‰ï¼Œé»˜è®¤å€¼ä¸º 5ã€‚
    è¿”å›:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„ç™¾åˆ†ä½å½’ä¸€åŒ–åçš„æ•°æ®ï¼ˆDataFrame æˆ– Seriesï¼‰ã€‚
    """
    # å°† Series è½¬æ¢ä¸º DataFrame è¿›è¡Œå¤„ç†
    is_series = isinstance(data, pd.Series)
    df = data.to_frame() if is_series else data.copy()
    
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("è¾“å…¥æ•°æ®çš„ index å¿…é¡»æ˜¯ DatetimeIndex ç±»å‹")
    
    # æå–åˆ†é’Ÿå¹¶åˆ†ç»„åˆ°æœ€è¿‘çš„æ•´ interval åˆ†é’Ÿ
    grouped_minutes = (df.index.minute // interval) * interval
    group_labels = df.index.hour * 60 + grouped_minutes
    
    # åˆå§‹åŒ–å­˜å‚¨ç»“æœ
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    for group_id in np.unique(group_labels):
        # æå–å½“å‰ç»„
        group_mask = group_labels == group_id
        group = df[group_mask]
        
        # å¯¹æ¯ç»„æŒ‰æ»šåŠ¨çª—å£è®¡ç®—ç™¾åˆ†ä½æ•°
        rolling_percentile = group.rolling(window=window, min_periods=min_periods).apply(
            lambda x: 100 * (x.iloc[-1] <= x).sum() / len(x), raw=False
        )
        
        # å­˜å‚¨ç»“æœ
        result.loc[group.index] = rolling_percentile
    
    # å¦‚æœè¾“å…¥æ˜¯ Seriesï¼Œåˆ™è¿”å› Series
    if is_series:
        return result.iloc[:, 0]
    return result


def rollingAggMinutePctl( # ä¿®æ­£æ­£è´Ÿå·
    data,
    window: str = "30d",
    min_periods: int = 1,
    interval: int = 5
):
    """
    æ¯åˆ†é’Ÿæ—¶é—´ç‚¹çš„æ»šåŠ¨çª—å£ç™¾åˆ†ä½è®¡ç®—ï¼Œå¹¶èšåˆåˆ°æ•´ interval åˆ†é’Ÿã€‚
    å‚æ•°:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯ DataFrame æˆ– Seriesï¼Œindex å¿…é¡»ä¸º DatetimeIndexã€‚
        window (str, optional): æ»šåŠ¨çª—å£å¤§å°ï¼Œæ”¯æŒ Pandas æ—¶é—´çª—å£ï¼ˆå¦‚ "30d" è¡¨ç¤º30å¤©ï¼‰ã€‚é»˜è®¤å€¼ä¸º "30d"ã€‚
        min_periods (int, optional): çª—å£ä¸­è¦æ±‚çš„æœ€å°‘è§‚å¯Ÿæ•°ï¼Œé»˜è®¤å€¼ä¸º 1ã€‚
        interval (int, optional): æ—¶é—´åˆ†ç»„çš„é—´éš”ï¼ˆä»¥åˆ†é’Ÿä¸ºå•ä½ï¼‰ï¼Œé»˜è®¤å€¼ä¸º 5ã€‚
    è¿”å›:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„ç™¾åˆ†ä½å½’ä¸€åŒ–åçš„æ•°æ®ï¼ˆDataFrame æˆ– Seriesï¼‰ã€‚
    """
    # å°† Series è½¬æ¢ä¸º DataFrame è¿›è¡Œå¤„ç†
    is_series = isinstance(data, pd.Series)
    df = data.to_frame() if is_series else data.copy()
    
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("è¾“å…¥æ•°æ®çš„ index å¿…é¡»æ˜¯ DatetimeIndex ç±»å‹")
    
    # æå–åˆ†é’Ÿå¹¶åˆ†ç»„åˆ°æœ€è¿‘çš„æ•´ interval åˆ†é’Ÿ
    grouped_minutes = (df.index.minute // interval) * interval
    group_labels = df.index.hour * 60 + grouped_minutes
    
    # åˆå§‹åŒ–å­˜å‚¨ç»“æœ
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    for group_id in np.unique(group_labels):
        # æå–å½“å‰ç»„
        group_mask = group_labels == group_id
        group = df[group_mask]
        
        # å¯¹æ¯ç»„æŒ‰æ»šåŠ¨çª—å£è®¡ç®—ç™¾åˆ†ä½æ•°
        rolling_percentile = group.rolling(window=window, min_periods=min_periods).apply(
            lambda x: (x.iloc[-1] >= x).sum() / len(x), raw=False
        )
        
        # å­˜å‚¨ç»“æœ
        result.loc[group.index] = rolling_percentile
    
    # å¦‚æœè¾“å…¥æ˜¯ Seriesï¼Œåˆ™è¿”å› Series
    if is_series:
        return result.iloc[:, 0]
    return result


def aggPctl( # ä¿®æ­£æ­£è´Ÿå·
    data,
    window: str = "30d",
    min_periods: int = 1,
    interval: int = 5
):
    """
    æ¯åˆ†é’Ÿæ—¶é—´ç‚¹çš„æ»šåŠ¨çª—å£ç™¾åˆ†ä½è®¡ç®—ï¼Œå¹¶èšåˆåˆ°æ•´ interval åˆ†é’Ÿã€‚
    å‚æ•°:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯ DataFrame æˆ– Seriesï¼Œindex å¿…é¡»ä¸º DatetimeIndexã€‚
        window (str, optional): æ»šåŠ¨çª—å£å¤§å°ï¼Œæ”¯æŒ Pandas æ—¶é—´çª—å£ï¼ˆå¦‚ "30d" è¡¨ç¤º30å¤©ï¼‰ã€‚é»˜è®¤å€¼ä¸º "30d"ã€‚
        min_periods (int, optional): çª—å£ä¸­è¦æ±‚çš„æœ€å°‘è§‚å¯Ÿæ•°ï¼Œé»˜è®¤å€¼ä¸º 1ã€‚
        interval (int, optional): æ—¶é—´åˆ†ç»„çš„é—´éš”ï¼ˆä»¥åˆ†é’Ÿä¸ºå•ä½ï¼‰ï¼Œé»˜è®¤å€¼ä¸º 5ã€‚
    è¿”å›:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„ç™¾åˆ†ä½å½’ä¸€åŒ–åçš„æ•°æ®ï¼ˆDataFrame æˆ– Seriesï¼‰ã€‚
    """
    # å°† Series è½¬æ¢ä¸º DataFrame è¿›è¡Œå¤„ç†
    is_series = isinstance(data, pd.Series)
    df = data.to_frame() if is_series else data.copy()
    
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("è¾“å…¥æ•°æ®çš„ index å¿…é¡»æ˜¯ DatetimeIndex ç±»å‹")
    
    # æå–åˆ†é’Ÿå¹¶åˆ†ç»„åˆ°æœ€è¿‘çš„æ•´ interval åˆ†é’Ÿ
    grouped_minutes = (df.index.minute // interval) * interval
    group_labels = df.index.hour * 60 + grouped_minutes
    
    # åˆå§‹åŒ–å­˜å‚¨ç»“æœ
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    for group_id in np.unique(group_labels):
        # æå–å½“å‰ç»„
        group_mask = group_labels == group_id
        group = df[group_mask]
        
        # å¯¹æ¯ç»„æŒ‰æ»šåŠ¨çª—å£è®¡ç®—ç™¾åˆ†ä½æ•°
        rolling_percentile = group.rolling(window=window, min_periods=min_periods).apply(
            lambda x: (x.iloc[-1] >= x).sum() / len(x), raw=False
        )
        
        # å­˜å‚¨ç»“æœ
        result.loc[group.index] = rolling_percentile
    
    # å¦‚æœè¾“å…¥æ˜¯ Seriesï¼Œåˆ™è¿”å› Series
    if is_series:
        return result.iloc[:, 0]
    return result


def rollingMinuteZScore(
    data,
    window: str = "30d",
    min_periods: int = 1,
    interval: int = 5
):
    """
    è®¡ç®—æ¯ä¸ªåˆ†é’Ÿæ—¶é—´ç‚¹åœ¨è¿‡å»åŒä¸€åˆ†ç»„åˆ†é’Ÿï¼ˆåŒæ¯”ï¼‰ä¸­çš„z-scoreï¼Œå¹¶èšåˆåˆ°æ•´intervalåˆ†é’Ÿã€‚
    
    å‚æ•°:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯ DataFrame æˆ– Seriesï¼Œindex å¿…é¡»ä¸º DatetimeIndexã€‚
        window (str, optional): æ»šåŠ¨çª—å£å¤§å°ï¼Œæ”¯æŒ Pandas æ—¶é—´çª—å£ï¼ˆå¦‚ "30d" è¡¨ç¤º30å¤©ï¼‰ã€‚é»˜è®¤å€¼ä¸º "30d"ã€‚
        min_periods (int, optional): çª—å£ä¸­è¦æ±‚çš„æœ€å°‘è§‚å¯Ÿæ•°ï¼Œé»˜è®¤å€¼ä¸º 1ã€‚
        interval (int, optional): æ—¶é—´åˆ†ç»„çš„é—´éš”ï¼ˆä»¥åˆ†é’Ÿä¸ºå•ä½ï¼‰ï¼Œé»˜è®¤å€¼ä¸º 5ã€‚
    
    è¿”å›:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„z-scoreæ ‡å‡†åŒ–åçš„æ•°æ®ï¼ˆDataFrame æˆ– Seriesï¼‰ã€‚
    """
    import pandas as pd
    import numpy as np
    
    # å°† Series è½¬æ¢ä¸º DataFrame è¿›è¡Œå¤„ç†
    is_series = isinstance(data, pd.Series)
    df = data.to_frame() if is_series else data.copy()
    
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("è¾“å…¥æ•°æ®çš„ index å¿…é¡»æ˜¯ DatetimeIndex ç±»å‹")
    
    # æå–åˆ†é’Ÿå¹¶åˆ†ç»„åˆ°æœ€è¿‘çš„æ•´ interval åˆ†é’Ÿ
    grouped_minutes = (df.index.minute // interval) * interval
    # åˆ›å»ºæ¯å¤©ä¸­çš„åˆ†é’Ÿæ ‡è¯†ç¬¦ï¼ˆ0-1439ï¼Œä»£è¡¨ä¸€å¤©ä¸­çš„æ¯ä¸€åˆ†é’Ÿï¼‰
    group_labels = df.index.hour * 60 + grouped_minutes
    
    # åˆå§‹åŒ–å­˜å‚¨ç»“æœ
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    for group_id in np.unique(group_labels):
        # æå–å½“å‰ç»„ï¼ˆåŒä¸€åˆ†é’Ÿç»„çš„æ‰€æœ‰å†å²æ•°æ®ï¼‰
        group_mask = group_labels == group_id
        group = df[group_mask]
        
        if group.empty:
            continue
            
        # æŒ‰æ—¶é—´æ’åºç¡®ä¿æ­£ç¡®çš„å†å²è®¡ç®—
        group = group.sort_index()
        
        # å¯¹æ¯ç»„æŒ‰æ»šåŠ¨çª—å£è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
        rolling_mean = group.rolling(window=window, min_periods=min_periods).mean()
        rolling_std = group.rolling(window=window, min_periods=min_periods).std()
        
        # è®¡ç®—z-score: (x - mean) / std
        # å¤„ç†æ ‡å‡†å·®ä¸º0çš„æƒ…å†µ
        z_scores = (group - rolling_mean) / rolling_std.replace(0, np.nan)
        
        # å¡«å……ç»“æœåˆ°ä¸»DataFrame
        result.loc[group.index] = z_scores
    
    # å¦‚æœè¾“å…¥æ˜¯ Seriesï¼Œåˆ™è¿”å› Series
    if is_series:
        return result.iloc[:, 0]
    
    return result


def aggZsc(
    data,
    window: str = "30d",
    min_periods: int = 1,
    interval: int = 5
):
    """
    è®¡ç®—æ¯ä¸ªåˆ†é’Ÿæ—¶é—´ç‚¹åœ¨è¿‡å»åŒä¸€åˆ†ç»„åˆ†é’Ÿï¼ˆåŒæ¯”ï¼‰ä¸­çš„z-scoreï¼Œå¹¶èšåˆåˆ°æ•´intervalåˆ†é’Ÿã€‚
    
    å‚æ•°:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯ DataFrame æˆ– Seriesï¼Œindex å¿…é¡»ä¸º DatetimeIndexã€‚
        window (str, optional): æ»šåŠ¨çª—å£å¤§å°ï¼Œæ”¯æŒ Pandas æ—¶é—´çª—å£ï¼ˆå¦‚ "30d" è¡¨ç¤º30å¤©ï¼‰ã€‚é»˜è®¤å€¼ä¸º "30d"ã€‚
        min_periods (int, optional): çª—å£ä¸­è¦æ±‚çš„æœ€å°‘è§‚å¯Ÿæ•°ï¼Œé»˜è®¤å€¼ä¸º 1ã€‚
        interval (int, optional): æ—¶é—´åˆ†ç»„çš„é—´éš”ï¼ˆä»¥åˆ†é’Ÿä¸ºå•ä½ï¼‰ï¼Œé»˜è®¤å€¼ä¸º 5ã€‚
    
    è¿”å›:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„z-scoreæ ‡å‡†åŒ–åçš„æ•°æ®ï¼ˆDataFrame æˆ– Seriesï¼‰ã€‚
    """
    import pandas as pd
    import numpy as np
    
    # å°† Series è½¬æ¢ä¸º DataFrame è¿›è¡Œå¤„ç†
    is_series = isinstance(data, pd.Series)
    df = data.to_frame() if is_series else data.copy()
    
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("è¾“å…¥æ•°æ®çš„ index å¿…é¡»æ˜¯ DatetimeIndex ç±»å‹")
    
    # æå–åˆ†é’Ÿå¹¶åˆ†ç»„åˆ°æœ€è¿‘çš„æ•´ interval åˆ†é’Ÿ
    grouped_minutes = (df.index.minute // interval) * interval
    # åˆ›å»ºæ¯å¤©ä¸­çš„åˆ†é’Ÿæ ‡è¯†ç¬¦ï¼ˆ0-1439ï¼Œä»£è¡¨ä¸€å¤©ä¸­çš„æ¯ä¸€åˆ†é’Ÿï¼‰
    group_labels = df.index.hour * 60 + grouped_minutes
    
    # åˆå§‹åŒ–å­˜å‚¨ç»“æœ
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    for group_id in np.unique(group_labels):
        # æå–å½“å‰ç»„ï¼ˆåŒä¸€åˆ†é’Ÿç»„çš„æ‰€æœ‰å†å²æ•°æ®ï¼‰
        group_mask = group_labels == group_id
        group = df[group_mask]
        
        if group.empty:
            continue
            
        # æŒ‰æ—¶é—´æ’åºç¡®ä¿æ­£ç¡®çš„å†å²è®¡ç®—
        group = group.sort_index()
        
        # å¯¹æ¯ç»„æŒ‰æ»šåŠ¨çª—å£è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
        rolling_mean = group.rolling(window=window, min_periods=min_periods).mean()
        rolling_std = group.rolling(window=window, min_periods=min_periods).std()
        
        # è®¡ç®—z-score: (x - mean) / std
        # å¤„ç†æ ‡å‡†å·®ä¸º0çš„æƒ…å†µ
        z_scores = (group - rolling_mean) / rolling_std.replace(0, np.nan)
        
        # å¡«å……ç»“æœåˆ°ä¸»DataFrame
        result.loc[group.index] = z_scores
    
    # å¦‚æœè¾“å…¥æ˜¯ Seriesï¼Œåˆ™è¿”å› Series
    if is_series:
        return result.iloc[:, 0]
    
    return result


def rollingMinuteDeMean(
    data,
    window: str = "30d",
    min_periods: int = 1,
    interval: int = 5
):
    """
    è®¡ç®—æ¯ä¸ªåˆ†é’Ÿæ—¶é—´ç‚¹åœ¨è¿‡å»åŒä¸€åˆ†ç»„åˆ†é’Ÿï¼ˆåŒæ¯”ï¼‰ä¸­çš„å»å‡å€¼ç»“æœï¼Œå¹¶èšåˆåˆ°æ•´intervalåˆ†é’Ÿã€‚
    åªæ‰§è¡Œä¸­å¿ƒåŒ–å¤„ç†ï¼ˆå‡å»å‡å€¼ï¼‰ï¼Œä¸è¿›è¡Œæ ‡å‡†å·®å½’ä¸€åŒ–ã€‚
    
    å‚æ•°:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯ DataFrame æˆ– Seriesï¼Œindex å¿…é¡»ä¸º DatetimeIndexã€‚
        window (str, optional): æ»šåŠ¨çª—å£å¤§å°ï¼Œæ”¯æŒ Pandas æ—¶é—´çª—å£ï¼ˆå¦‚ "30d" è¡¨ç¤º30å¤©ï¼‰ã€‚é»˜è®¤å€¼ä¸º "30d"ã€‚
        min_periods (int, optional): çª—å£ä¸­è¦æ±‚çš„æœ€å°‘è§‚å¯Ÿæ•°ï¼Œé»˜è®¤å€¼ä¸º 1ã€‚
        interval (int, optional): æ—¶é—´åˆ†ç»„çš„é—´éš”ï¼ˆä»¥åˆ†é’Ÿä¸ºå•ä½ï¼‰ï¼Œé»˜è®¤å€¼ä¸º 5ã€‚
    
    è¿”å›:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„å»å‡å€¼åçš„æ•°æ®ï¼ˆDataFrame æˆ– Seriesï¼‰ã€‚
    """
    import pandas as pd
    import numpy as np
    
    # å°† Series è½¬æ¢ä¸º DataFrame è¿›è¡Œå¤„ç†
    is_series = isinstance(data, pd.Series)
    df = data.to_frame() if is_series else data.copy()
    
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("è¾“å…¥æ•°æ®çš„ index å¿…é¡»æ˜¯ DatetimeIndex ç±»å‹")
    
    # æå–åˆ†é’Ÿå¹¶åˆ†ç»„åˆ°æœ€è¿‘çš„æ•´ interval åˆ†é’Ÿ
    grouped_minutes = (df.index.minute // interval) * interval
    # åˆ›å»ºæ¯å¤©ä¸­çš„åˆ†é’Ÿæ ‡è¯†ç¬¦ï¼ˆ0-1439ï¼Œä»£è¡¨ä¸€å¤©ä¸­çš„æ¯ä¸€åˆ†é’Ÿï¼‰
    group_labels = df.index.hour * 60 + grouped_minutes
    
    # åˆå§‹åŒ–å­˜å‚¨ç»“æœ
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    for group_id in np.unique(group_labels):
        # æå–å½“å‰ç»„ï¼ˆåŒä¸€åˆ†é’Ÿç»„çš„æ‰€æœ‰å†å²æ•°æ®ï¼‰
        group_mask = group_labels == group_id
        group = df[group_mask]
        
        if group.empty:
            continue
            
        # æŒ‰æ—¶é—´æ’åºç¡®ä¿æ­£ç¡®çš„å†å²è®¡ç®—
        group = group.sort_index()
        
        # å¯¹æ¯ç»„æŒ‰æ»šåŠ¨çª—å£è®¡ç®—å‡å€¼
        rolling_mean = group.rolling(window=window, min_periods=min_periods).mean()
        
        # åªæ‰§è¡Œå»å‡å€¼æ“ä½œ: x - mean
        de_meaned = group - rolling_mean
        
        # å¡«å……ç»“æœåˆ°ä¸»DataFrame
        result.loc[group.index] = de_meaned
    
    # å¦‚æœè¾“å…¥æ˜¯ Seriesï¼Œåˆ™è¿”å› Series
    if is_series:
        return result.iloc[:, 0]
    
    return result


def aggDmean(
    data,
    window: str = "30d",
    min_periods: int = 1,
    interval: int = 5
):
    """
    è®¡ç®—æ¯ä¸ªåˆ†é’Ÿæ—¶é—´ç‚¹åœ¨è¿‡å»åŒä¸€åˆ†ç»„åˆ†é’Ÿï¼ˆåŒæ¯”ï¼‰ä¸­çš„å»å‡å€¼ç»“æœï¼Œå¹¶èšåˆåˆ°æ•´intervalåˆ†é’Ÿã€‚
    åªæ‰§è¡Œä¸­å¿ƒåŒ–å¤„ç†ï¼ˆå‡å»å‡å€¼ï¼‰ï¼Œä¸è¿›è¡Œæ ‡å‡†å·®å½’ä¸€åŒ–ã€‚
    
    å‚æ•°:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯ DataFrame æˆ– Seriesï¼Œindex å¿…é¡»ä¸º DatetimeIndexã€‚
        window (str, optional): æ»šåŠ¨çª—å£å¤§å°ï¼Œæ”¯æŒ Pandas æ—¶é—´çª—å£ï¼ˆå¦‚ "30d" è¡¨ç¤º30å¤©ï¼‰ã€‚é»˜è®¤å€¼ä¸º "30d"ã€‚
        min_periods (int, optional): çª—å£ä¸­è¦æ±‚çš„æœ€å°‘è§‚å¯Ÿæ•°ï¼Œé»˜è®¤å€¼ä¸º 1ã€‚
        interval (int, optional): æ—¶é—´åˆ†ç»„çš„é—´éš”ï¼ˆä»¥åˆ†é’Ÿä¸ºå•ä½ï¼‰ï¼Œé»˜è®¤å€¼ä¸º 5ã€‚
    
    è¿”å›:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„å»å‡å€¼åçš„æ•°æ®ï¼ˆDataFrame æˆ– Seriesï¼‰ã€‚
    """
    import pandas as pd
    import numpy as np
    
    # å°† Series è½¬æ¢ä¸º DataFrame è¿›è¡Œå¤„ç†
    is_series = isinstance(data, pd.Series)
    df = data.to_frame() if is_series else data.copy()
    
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("è¾“å…¥æ•°æ®çš„ index å¿…é¡»æ˜¯ DatetimeIndex ç±»å‹")
    
    # æå–åˆ†é’Ÿå¹¶åˆ†ç»„åˆ°æœ€è¿‘çš„æ•´ interval åˆ†é’Ÿ
    grouped_minutes = (df.index.minute // interval) * interval
    # åˆ›å»ºæ¯å¤©ä¸­çš„åˆ†é’Ÿæ ‡è¯†ç¬¦ï¼ˆ0-1439ï¼Œä»£è¡¨ä¸€å¤©ä¸­çš„æ¯ä¸€åˆ†é’Ÿï¼‰
    group_labels = df.index.hour * 60 + grouped_minutes
    
    # åˆå§‹åŒ–å­˜å‚¨ç»“æœ
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    for group_id in np.unique(group_labels):
        # æå–å½“å‰ç»„ï¼ˆåŒä¸€åˆ†é’Ÿç»„çš„æ‰€æœ‰å†å²æ•°æ®ï¼‰
        group_mask = group_labels == group_id
        group = df[group_mask]
        
        if group.empty:
            continue
            
        # æŒ‰æ—¶é—´æ’åºç¡®ä¿æ­£ç¡®çš„å†å²è®¡ç®—
        group = group.sort_index()
        
        # å¯¹æ¯ç»„æŒ‰æ»šåŠ¨çª—å£è®¡ç®—å‡å€¼
        rolling_mean = group.rolling(window=window, min_periods=min_periods).mean()
        
        # åªæ‰§è¡Œå»å‡å€¼æ“ä½œ: x - mean
        de_meaned = group - rolling_mean
        
        # å¡«å……ç»“æœåˆ°ä¸»DataFrame
        result.loc[group.index] = de_meaned
    
    # å¦‚æœè¾“å…¥æ˜¯ Seriesï¼Œåˆ™è¿”å› Series
    if is_series:
        return result.iloc[:, 0]
    
    return result


# %%
def minmax_scale(df: pd.DataFrame, window=20, min_periods=10, quantile=0.05) -> pd.DataFrame:
    """
    æ»šåŠ¨çª—å£åˆ†ä½æ•°å½’ä¸€åŒ–ã€‚

    å‚æ•°:
        df (pd.DataFrame): ç”¨äºè®¡ç®—æ»šåŠ¨åˆ†ä½æ•°å½’ä¸€åŒ–çš„å˜é‡
        step (int, optional): è®¡ç®—å½’ä¸€åŒ–æ—¶çš„æ­¥é•¿ã€‚é»˜è®¤å€¼ä¸º1ã€‚
        window (int, optional): æ»šåŠ¨çª—å£å¤§å°ã€‚é»˜è®¤å€¼ä¸º20ã€‚
        min_periods (int, optional): çª—å£ä¸­è¦æ±‚çš„æœ€å°‘è§‚å¯Ÿæ•°ã€‚é»˜è®¤å€¼ä¸º10ã€‚
        quantile (float, optional): ç”¨äºå½’ä¸€åŒ–çš„åˆ†ä½æ•°ã€‚é»˜è®¤å€¼ä¸º0.05ï¼Œå³5%ã€‚

    è¿”å›:
        pd.DataFrame: å½’ä¸€åŒ–åçš„DataFrame
    """
    
    # å®šä¹‰5%å’Œ95%åˆ†ä½æ•°
    lower_quantile = quantile
    upper_quantile = 1 - quantile
    
    # è®¡ç®—æ»šåŠ¨çª—å£çš„åˆ†ä½æ•°
    df_lower = df.rolling(window=window, min_periods=min_periods).quantile(lower_quantile)
    df_upper = df.rolling(window=window, min_periods=min_periods).quantile(upper_quantile)
    
    # è¿›è¡Œåˆ†ä½æ•°å½’ä¸€åŒ–
    df_quantile_scaled = (df - df_lower) / (df_upper - df_lower).replace(0, np.nan)
    
    # è£å‰ªç»“æœä½¿å…¶åœ¨ 0 å’Œ 1 ä¹‹é—´
    df_quantile_scaled = df_quantile_scaled.clip(lower=0, upper=1)
    
    return df_quantile_scaled


def minmax(df: pd.DataFrame, window=20, min_periods=10, quantile=0.05) -> pd.DataFrame:
    """
    æ»šåŠ¨çª—å£åˆ†ä½æ•°å½’ä¸€åŒ–ã€‚

    å‚æ•°:
        df (pd.DataFrame): ç”¨äºè®¡ç®—æ»šåŠ¨åˆ†ä½æ•°å½’ä¸€åŒ–çš„å˜é‡
        step (int, optional): è®¡ç®—å½’ä¸€åŒ–æ—¶çš„æ­¥é•¿ã€‚é»˜è®¤å€¼ä¸º1ã€‚
        window (int, optional): æ»šåŠ¨çª—å£å¤§å°ã€‚é»˜è®¤å€¼ä¸º20ã€‚
        min_periods (int, optional): çª—å£ä¸­è¦æ±‚çš„æœ€å°‘è§‚å¯Ÿæ•°ã€‚é»˜è®¤å€¼ä¸º10ã€‚
        quantile (float, optional): ç”¨äºå½’ä¸€åŒ–çš„åˆ†ä½æ•°ã€‚é»˜è®¤å€¼ä¸º0.05ï¼Œå³5%ã€‚

    è¿”å›:
        pd.DataFrame: å½’ä¸€åŒ–åçš„DataFrame
    """
    
    # å®šä¹‰5%å’Œ95%åˆ†ä½æ•°
    lower_quantile = quantile
    upper_quantile = 1 - quantile
    
    # è®¡ç®—æ»šåŠ¨çª—å£çš„åˆ†ä½æ•°
    df_lower = df.rolling(window=window, min_periods=min_periods).quantile(lower_quantile)
    df_upper = df.rolling(window=window, min_periods=min_periods).quantile(upper_quantile)
    
    # è¿›è¡Œåˆ†ä½æ•°å½’ä¸€åŒ–
    df_quantile_scaled = (df - df_lower) / (df_upper - df_lower).replace(0, np.nan)
    
    # è£å‰ªç»“æœä½¿å…¶åœ¨ 0 å’Œ 1 ä¹‹é—´
    df_quantile_scaled = df_quantile_scaled.clip(lower=0, upper=1)
    
    return df_quantile_scaled


# =============================================================================
# # Numba å¹¶è¡Œæ»šåŠ¨åˆ†ä½å½’ä¸€åŒ–å®ç°ï¼ˆä¿®å¤ window è¾¹ç•Œé—®é¢˜ï¼‰
# @njit(parallel=True)
# def rolling_quantile_vectorized(data, window, lower_q, upper_q):
#     n_rows, n_cols = data.shape
#     result = np.empty((n_rows, n_cols), dtype=np.float32)
# 
#     for j in prange(n_cols):  # å¹¶è¡Œæ¯åˆ—
#         col = data[:, j]
#         lower = np.full(n_rows, np.nan, dtype=np.float32)
#         upper = np.full(n_rows, np.nan, dtype=np.float32)
# 
#         for i in range(n_rows):
#             start = max(0, i - window + 1)
#             window_vals = col[start:i + 1]
#             lower[i] = np.quantile(window_vals, lower_q)
#             upper[i] = np.quantile(window_vals, upper_q)
# 
#         for i in range(n_rows):
#             denom = upper[i] - lower[i]
#             if np.isnan(denom) or denom == 0:
#                 result[i, j] = np.nan
#             else:
#                 val = (col[i] - lower[i]) / denom
#                 result[i, j] = min(1.0, max(0.0, val))
# 
#     return result
# 
# 
# def minmax_scale_numba_parallel(df: pd.DataFrame, window=20, quantile=0.05) -> pd.DataFrame:
#     df_filled = df.fillna(0)  # å…ˆå¡«å…… NaN
#     data = df_filled.values.astype(np.float32)
#     scaled = rolling_quantile_vectorized(data, window, quantile, 1 - quantile)
#     return pd.DataFrame(scaled, index=df.index, columns=df.columns)
# 
# =============================================================================


# =============================================================================
# # å¯¹å•åˆ—åš rolling quantile
# @njit(parallel=True)
# def rolling_quantile_numba(arr, window, quantile):
#     n = len(arr)
#     result = np.full(n, np.nan)
# 
#     for i in prange(window - 1, n):
#         start = max(0, i - window + 1)
#         window_vals = arr[start:i + 1]
#         result[i] = np.quantile(window_vals, quantile)
# 
#     return result
# 
# # å¯¹æ•´ä¸ª DataFrame åšåˆ†ä½æ•°å½’ä¸€åŒ–ï¼Œå¹¶æ‰“å°è¿›åº¦
# def minmax_scale_numba_parallel(df: pd.DataFrame, window=20, quantile=0.05) -> pd.DataFrame:
#     lower_quantile = quantile
#     upper_quantile = 1 - quantile
#     result = pd.DataFrame(index=df.index, columns=df.columns, dtype=np.float32)
# 
#     total_cols = len(df.columns)
# 
#     for idx, col in enumerate(df.columns):
#         breakpoint()
#         series = df[col].fillna(0).values.astype(np.float32)
#         lower = rolling_quantile_numba(series, window, lower_quantile)
#         upper = rolling_quantile_numba(series, window, upper_quantile)
#         scaled = (series - lower) / (upper - lower + 1e-12)
#         scaled = np.clip(scaled, 0, 1)
#         result[col] = scaled
# 
#         # æ‰“å°è¿›åº¦ï¼ˆæ¯å¤„ç†å®Œ50åˆ—æ›´æ–°ä¸€æ¬¡ï¼Œæˆ–æœ€åä¸€åˆ—ï¼‰
#         if (idx + 1) % 10 == 0 or idx == total_cols - 1:
#             print(f"[minmax_scale_numba] Processed {idx + 1}/{total_cols} columns")
# 
#     return result
# =============================================================================


import numpy as np
import pandas as pd
from numba import njit, prange, set_num_threads
from concurrent.futures import ProcessPoolExecutor, as_completed
from tqdm import tqdm

# =============================================================================
# @njit(parallel=True)
# def rolling_quantile_numba(arr, window, quantile):
#     n = len(arr)
#     result = np.full(n, np.nan, dtype=np.float32)
#     for i in prange(window - 1, n):
#         start = max(0, i - window + 1)
#         window_vals = arr[start:i + 1]
#         result[i] = np.quantile(window_vals, quantile)
#     return result
# 
# def process_column_block(df_block: pd.DataFrame, window: int, quantile: float, threads_per_worker: int, block_idx: int):
#     set_num_threads(threads_per_worker)
#     lower_q = quantile
#     upper_q = 1 - quantile
#     result_dict = {}
# 
#     total_cols = len(df_block.columns)
#     for idx, col in enumerate(df_block.columns):
#         series = df_block[col].values
#         lower = rolling_quantile_numba(series, window, lower_q)
#         upper = rolling_quantile_numba(series, window, upper_q)
#         scaled = (series - lower) / (upper - lower + 1e-12)
#         result_dict[col] = np.clip(scaled, 0, 1)
# 
#         # if (idx + 1) % 50 == 0 or idx == total_cols - 1:
#         #     print(f"[Worker-{block_idx}] Processed {idx + 1}/{total_cols} columns")
# 
#     return block_idx, result_dict
# =============================================================================

def process_column_block(df_block, window, quantile, block_idx):
    lower = df_block.rolling(window=window, min_periods=10).quantile(quantile)
    upper = df_block.rolling(window=window, min_periods=10).quantile(1 - quantile)
    scaled = (df_block - lower) / (upper - lower + 1e-12)
    scaled = scaled.clip(lower=0, upper=1)
    # print(f"[Worker-{block_idx}] Done with pandas.")
    return block_idx, scaled


def minmax_scale_numba_parallel(df: pd.DataFrame, window=20, quantile=0.05,
                                 n_jobs=150, block_size=5, threads_per_worker=10):
    df = df.fillna(0).astype(np.float32)
    col_blocks = [df.columns[i:i+block_size] for i in range(0, len(df.columns), block_size)]
    result = pd.DataFrame(index=df.index, columns=df.columns, dtype=np.float32)
    total_blocks = len(col_blocks)

    print(f"[Main] Launching {total_blocks} blocks with {n_jobs} processes...")

    with ProcessPoolExecutor(max_workers=n_jobs) as executor:
        future_to_idx = {}
        for block_idx, cols in enumerate(col_blocks):
            df_block = df[cols]
            future = executor.submit(process_column_block, df_block, window, quantile, block_idx) 
            future_to_idx[future] = (block_idx, cols)

        with tqdm(total=total_blocks, desc="Progress") as pbar:
            for future in as_completed(future_to_idx):
                block_idx, cols = future_to_idx[future]
                _, block_result = future.result()
                for col in cols:
                    result[col] = block_result[col]
                pbar.update(1)

    print("[Main] All blocks completed and written into result DataFrame.")
    return result


def rlPctl(data_df, window):
    """
    è®¡ç®—æ¯ä¸ªä½ç½®çš„å½“å‰å€¼åœ¨æ»šåŠ¨çª—å£å†å²å€¼ä¸­çš„åˆ†ä½æ•°ã€‚

    å‚æ•°ï¼š
    data_df (pd.DataFrame): è¾“å…¥çš„æ•°æ® DataFrameã€‚
    window (int): æ»šåŠ¨çª—å£çš„å¤§å°ã€‚

    è¿”å›ï¼š
    pd.DataFrame: æ¯ä¸ªä½ç½®çš„å½“å‰å€¼åœ¨æ»šåŠ¨çª—å£ä¸­çš„åˆ†ä½æ•°ã€‚
    """
    def calc_percentile(series):
        current_value = series.iloc[-1]
        rolling_window = series.iloc[:-1].dropna()
        if len(rolling_window) == 0:
            return np.nan
        return (rolling_window <= current_value).mean()

    return data_df.rolling(window, min_periods=1).apply(calc_percentile, raw=False)


def minmaxSep(df: pd.DataFrame, window=20, min_periods=10, quantile=0.05) -> pd.DataFrame:
    """
    æ»šåŠ¨çª—å£åˆ†ä½æ•°å½’ä¸€åŒ–ï¼Œæ­£å€¼å’Œè´Ÿå€¼åˆ†åˆ«å½’ä¸€åŒ–ã€‚

    å‚æ•°:
        df (pd.DataFrame): ç”¨äºè®¡ç®—æ»šåŠ¨åˆ†ä½æ•°å½’ä¸€åŒ–çš„å˜é‡
        step (int, optional): è®¡ç®—å½’ä¸€åŒ–æ—¶çš„æ­¥é•¿ã€‚é»˜è®¤å€¼ä¸º1ã€‚
        window (int, optional): æ»šåŠ¨çª—å£å¤§å°ã€‚é»˜è®¤å€¼ä¸º20ã€‚
        min_periods (int, optional): çª—å£ä¸­è¦æ±‚çš„æœ€å°‘è§‚å¯Ÿæ•°ã€‚é»˜è®¤å€¼ä¸º10ã€‚
        quantile (float, optional): ç”¨äºå½’ä¸€åŒ–çš„åˆ†ä½æ•°ã€‚é»˜è®¤å€¼ä¸º0.05ï¼Œå³5%ã€‚

    è¿”å›:
        pd.DataFrame: å½’ä¸€åŒ–åçš„DataFrame
    """
    # å®šä¹‰5%å’Œ95%åˆ†ä½æ•°
    lower_quantile = quantile
    upper_quantile = 1 - quantile
    
    # åˆ›å»ºæ­£å€¼å’Œè´Ÿå€¼çš„æ©ç 
    positive_mask = df > 0
    negative_mask = df < 0
    
    # è®¡ç®—æ­£å€¼éƒ¨åˆ†çš„æ»šåŠ¨çª—å£åˆ†ä½æ•°
    df_positive = df[positive_mask]
    df_positive_lower = df_positive.rolling(window=window, min_periods=min_periods).quantile(lower_quantile)
    df_positive_upper = df_positive.rolling(window=window, min_periods=min_periods).quantile(upper_quantile)
    
    # è®¡ç®—è´Ÿå€¼éƒ¨åˆ†çš„æ»šåŠ¨çª—å£åˆ†ä½æ•°
    df_negative = df[negative_mask]
    df_negative_lower = df_negative.rolling(window=window, min_periods=min_periods).quantile(lower_quantile)
    df_negative_upper = df_negative.rolling(window=window, min_periods=min_periods).quantile(upper_quantile)
    
    # åˆå§‹åŒ–å½’ä¸€åŒ–åçš„DataFrame
    df_quantile_scaled = pd.DataFrame(index=df.index, columns=df.columns)
    
    # å¯¹æ­£å€¼éƒ¨åˆ†è¿›è¡Œå½’ä¸€åŒ–ï¼Œä½¿å…¶åœ¨ 0.5 åˆ° 1 ä¹‹é—´
    df_quantile_scaled[positive_mask] = 0.5 + 0.5 * ((df_positive - df_positive_lower) / (df_positive_upper - df_positive_lower).replace(0, np.nan))
    
    # å¯¹è´Ÿå€¼éƒ¨åˆ†è¿›è¡Œå½’ä¸€åŒ–ï¼Œä½¿å…¶åœ¨ 0 åˆ° 0.5 ä¹‹é—´
    df_quantile_scaled[negative_mask] = 0.5 * ((df_negative - df_negative_upper) / (df_negative_lower - df_negative_upper).replace(0, np.nan))
    
    # è£å‰ªç»“æœä½¿å…¶åœ¨ 0 å’Œ 1 ä¹‹é—´
    df_quantile_scaled = df_quantile_scaled.clip(lower=0, upper=1)
    
    return df_quantile_scaled


# %% Non-Linear
def bimodal_sin(df, power=2):
    """
    å¯¹æ•´ä¸ª DataFrame åº”ç”¨åŒå³°å˜æ¢ï¼ˆå…ƒç´ å€¼éœ€å·²å½’ä¸€åŒ–ï¼‰ï¼šy = 1 - (sin(pi * x)) ** power

    å‚æ•°:
    - df: è¾“å…¥ DataFrameï¼ˆæ¯ä¸ªå…ƒç´ éƒ½åº”åœ¨ [0, 1] ä¹‹é—´ï¼‰
    - power: å¹‚æ¬¡æ•°ï¼Œæ§åˆ¶ä¸¤å¤´é«˜ã€ä¸­é—´ä½çš„ç¨‹åº¦

    è¿”å›:
    - ä¸€ä¸ªæ–°çš„ DataFrameï¼Œç»“æ„å’ŒåŸ df ç›¸åŒ
    """
    return 1 - (np.sin(np.pi * df)) ** power


def absv(df):
    return df.abs()
