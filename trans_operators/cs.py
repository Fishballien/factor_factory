# -*- coding: utf-8 -*-
"""
Created on Thu Dec  5 09:57:55 2024

@author: Xintang Zheng

æ˜Ÿæ˜Ÿ: â˜… â˜† âœª âœ© ğŸŒŸ â­ âœ¨ ğŸŒ  ğŸ’« â­ï¸
å‹¾å‹¾å‰å‰: âœ“ âœ” âœ• âœ– âœ… â
æŠ¥è­¦å•¦: âš  â“˜ â„¹ â˜£
ç®­å¤´: â” âœ â™ â¤ â¥ â†© â†ª
emoji: ğŸ”” â³ â° ğŸ”’ ğŸ”“ ğŸ›‘ ğŸš« â— â“ âŒ â­• ğŸš€ ğŸ”¥ ğŸ’§ ğŸ’¡ ğŸµ ğŸ¶ ğŸ§­ ğŸ“… ğŸ¤” ğŸ§® ğŸ”¢ ğŸ“Š ğŸ“ˆ ğŸ“‰ ğŸ§  ğŸ“

"""
# %% imports
import pandas as pd
import numpy as np
from scipy.stats import skew, kurtosis, entropy


# %%
def csmean(df):
    """
    ä½¿ç”¨ NumPy çŸ©é˜µè®¡ç®— DataFrame æ¯è¡Œçš„å¹³å‡å€¼ã€‚
    """
    row_means = np.nanmean(df.to_numpy(), axis=1)
    return pd.Series(row_means, index=df.index)


def cssum(df):
    """
    ä½¿ç”¨ NumPy çŸ©é˜µè®¡ç®— DataFrame æ¯è¡Œçš„å¹³å‡å€¼ã€‚
    """
    row_sum = np.nansum(df.to_numpy(), axis=1)
    return pd.Series(row_sum, index=df.index)

# =============================================================================
# def csskew(df):
#     """
#     è®¡ç®—æ¯è¡Œçš„ååº¦ã€‚
#     """
#     def row_skewness(row):
#         return pd.Series(row).skew(skipna=True)
# 
#     return df.apply(row_skewness, axis=1)
# 
# 
# def cssci(df):
#     """
#     è®¡ç®—ç¬¦å·ååŒæ€§æŒ‡æ•°ï¼ˆSCIï¼‰ã€‚
#     """
#     def row_sci(row):
#         pos_ratio = np.sum(row > 0) / len(row)
#         neg_ratio = np.sum(row < 0) / len(row)
#         return pos_ratio - neg_ratio
# 
#     return df.apply(row_sci, axis=1)
# 
# 
# def cswvar(df):
#     """
#     è®¡ç®—ç¬¦å·åŠ æƒçš„æ–¹å·®ã€‚
#     """
#     def row_weighted_variance(row):
#         row = row.dropna()
#         weights = np.sign(row) * np.abs(row)
#         mean_weighted = np.mean(weights)
#         return np.mean((weights - mean_weighted) ** 2)
# 
#     return df.apply(row_weighted_variance, axis=1)
# 
# 
# def csaci(df):
#     """
#     è®¡ç®—èšåˆæ€§æŒ‡æ•°ï¼ˆACIï¼‰ã€‚
#     """
#     def row_aci(row):
#         pairs = [(row[i], row[j]) for i in range(len(row)) for j in range(i + 1, len(row))]
#         concordance = np.sum(np.sign(x[0] * x[1]) for x in pairs) / len(pairs)
#         return concordance
# 
#     return df.apply(row_aci, axis=1)
# 
# 
# def csgci(df, alpha=1, beta=1, gamma=1):
#     """
#     è®¡ç®—å…¨å±€ååŒæ€§æŒ‡æ•°ï¼ˆGCIï¼‰ã€‚
#     """
#     mean_diff = csmean(df)
#     sci = cssci(df)
#     weighted_var = cswvar(df)
# 
#     return alpha * mean_diff + beta * sci + gamma * weighted_var
# 
# 
# def csswsm(df):
#     """
#     è®¡ç®—ç¬¦å·åŠ æƒçš„äºŒé˜¶çŸ©ç‰¹å¾ã€‚
#     
#     å‚æ•°:
#     df (pd.DataFrame): è¾“å…¥æ•°æ®æ¡†ã€‚
#     
#     è¿”å›:
#     pd.Series: æ¯è¡Œçš„ç¬¦å·åŠ æƒäºŒé˜¶çŸ©ç‰¹å¾å€¼ã€‚
#     """
#     def row_sign_weighted_second_moment(row):
#         row = row.dropna()
#         weights = np.sign(row) * row**2
#         total_weight = np.sum(np.abs(row)**2)
#         if total_weight == 0:
#             return 0
#         return np.sum(weights) / total_weight
# 
#     return df.apply(row_sign_weighted_second_moment, axis=1)
# =============================================================================


# %%
def cs_adjusted_cv(df):
    """
    è®¡ç®—ç›¸å¯¹äº0.5çš„è°ƒæ•´å˜å¼‚ç³»æ•°
    è¿”å›ï¼šSeriesï¼Œå€¼è¶Šé«˜è¡¨ç¤ºä¸€è‡´æ€§è¶Šå¼º
    """
    # è®¡ç®—ä¸0.5çš„è·ç¦»
    distance_from_mid = df.apply(lambda x: np.abs(x - 0.5), axis=1)
    mean_distance = distance_from_mid.mean(axis=1)
    # è®¡ç®—è¿™äº›è·ç¦»çš„æ ‡å‡†å·®
    std_distance = distance_from_mid.apply(lambda x: np.nanstd(x), axis=1)
    # è°ƒæ•´çš„å˜å¼‚ç³»æ•°
    return 1 - (std_distance / (mean_distance + 1e-10))  # åŠ å°å€¼é¿å…é™¤é›¶

def cs_direction_consistency(df):
    """
    è®¡ç®—æˆªé¢ä¸€è‡´æ€§æ–¹å‘æŒ‡æ ‡
    è¿”å›ï¼šSeriesï¼Œæ­£å€¼è¡¨ç¤ºä¸€è‡´åå¤š(>0.5)ï¼Œè´Ÿå€¼è¡¨ç¤ºä¸€è‡´åç©º(<0.5)ï¼ŒèŒƒå›´[-1,1]
    """
    # è®¡ç®—é«˜äº0.5çš„æ¯”ä¾‹
    above_ratio = df.apply(lambda x: np.mean(x > 0.5), axis=1)
    # è®¡ç®—ä½äº0.5çš„æ¯”ä¾‹
    below_ratio = df.apply(lambda x: np.mean(x < 0.5), axis=1)
    # æ–¹å‘ä¸€è‡´æ€§ï¼šä»-1(å…¨éƒ¨<0.5)åˆ°1(å…¨éƒ¨>0.5)
    return above_ratio - below_ratio

def cs_polarization(df):
    """
    è®¡ç®—æˆªé¢æåŒ–æŒ‡æ ‡
    è¿”å›ï¼šSeriesï¼Œå€¼è¶Šé«˜è¡¨ç¤ºæ•°æ®è¶Šè¿œç¦»0.5ï¼ŒèŒƒå›´[0,0.5]
    """
    # è®¡ç®—ä¸0.5çš„è·ç¦»
    distance_from_mid = df.apply(lambda x: np.abs(x - 0.5), axis=1)
    # è¿”å›å¹³å‡è·ç¦»ï¼Œæœ€å¤§ä¸º0.5
    return distance_from_mid.mean(axis=1)

def cs_concentration(df):
    """
    è®¡ç®—æˆªé¢é›†ä¸­åº¦æŒ‡æ ‡
    è¿”å›ï¼šSeriesï¼Œå€¼è¶Šé«˜è¡¨ç¤ºä¸€è‡´æ€§è¶Šå¼ºï¼ŒèŒƒå›´[0,1]
    """
    # è®¡ç®—ä¸å‡å€¼çš„å¹³å‡ç»å¯¹åå·®
    mad = df.apply(lambda x: np.nanmean(np.abs(x - np.nanmean(x))), axis=1)
    # é›†ä¸­åº¦ï¼ˆ1å‡å»å½’ä¸€åŒ–çš„MADï¼‰
    return 1 - (mad / 0.5)

def cs_direction(df):
    """
    è®¡ç®—æˆªé¢æ–¹å‘æŒ‡æ ‡
    è¿”å›ï¼šSeriesï¼Œæ­£è¡¨ç¤ºåå¤šï¼Œè´Ÿè¡¨ç¤ºåç©ºï¼ŒèŒƒå›´[-1,1]
    """
    means = csmean(df)
    # æ–¹å‘ï¼ˆç›¸å¯¹äº0.5çš„ç¬¦å·è·ç¦»ï¼‰
    return (means - 0.5) * 2  # ç¼©æ”¾åˆ°[-1,1]

def cs_consensus_strength(df):
    """
    è®¡ç®—ä¸€è‡´æ€§å¼ºåº¦
    è¿”å›ï¼šSeriesï¼Œæ­£å€¼è¡¨ç¤ºä¸€è‡´åå¤šï¼Œè´Ÿå€¼è¡¨ç¤ºä¸€è‡´åç©ºï¼Œç»å¯¹å€¼è¶Šå¤§è¡¨ç¤ºä¸€è‡´æ€§è¶Šå¼ºï¼ŒèŒƒå›´[-1,1]
    """
    # ä¸0.5çš„å¹³å‡åå·®(å¸¦ç¬¦å·)
    mean_deviation = df.apply(lambda x: np.mean(x - 0.5), axis=1)
    # æœ€å¤§å¯èƒ½åå·®ä¸º0.5ï¼Œæ‰€ä»¥ä¹˜ä»¥2ä½¿èŒƒå›´ä¸º[-1,1]
    return mean_deviation * 2

def cs_skewness(df):
    """
    è®¡ç®—æˆªé¢ååº¦
    è¿”å›ï¼šSeriesï¼Œæ­£å€¼è¡¨ç¤ºåˆ†å¸ƒåå‘1ï¼Œè´Ÿå€¼è¡¨ç¤ºåˆ†å¸ƒåå‘0
    """
    return df.apply(lambda x: skew(x.dropna()), axis=1)

def cs_kurtosis(df):
    """
    è®¡ç®—æˆªé¢å³°åº¦
    è¿”å›ï¼šSeriesï¼Œé«˜å€¼è¡¨ç¤ºåˆ†å¸ƒæ›´é›†ä¸­
    """
    return df.apply(lambda x: kurtosis(x.dropna(), fisher=False), axis=1)

def cs_entropy(df):
    """
    è®¡ç®—æˆªé¢ç†µ
    è¿”å›ï¼šSeriesï¼Œå€¼è¶Šä½è¡¨ç¤ºä¸€è‡´æ€§è¶Šé«˜
    """
    def calc_entropy(x):
        x = x.dropna()
        # å¯¹äº0-1å€¼ï¼Œå…ˆè¿›è¡Œåˆ†ç®±
        hist, _ = np.histogram(x, bins=10, range=(0, 1), density=True)
        hist = hist / hist.sum()  # å½’ä¸€åŒ–
        return entropy(hist + 1e-10)  # æ·»åŠ å°å€¼é¿å…log(0)
    
    return df.apply(calc_entropy, axis=1)

def cs_gini(df):
    """
    è®¡ç®—æˆªé¢åŸºå°¼ç³»æ•°
    è¿”å›ï¼šSeriesï¼Œå€¼è¶Šé«˜è¡¨ç¤ºä¸å¹³ç­‰ç¨‹åº¦è¶Šé«˜ï¼ŒèŒƒå›´[0,1]
    """
    def gini(x):
        x = np.sort(x.dropna())
        n = len(x)
        cumx = np.cumsum(x)
        return (n + 1 - 2 * np.sum(cumx) / cumx[-1]) / n if n > 0 and cumx[-1] > 0 else 0
    
    return df.apply(gini, axis=1)

def cs_iqr(df):
    """
    è®¡ç®—æˆªé¢å››åˆ†ä½å·®
    è¿”å›ï¼šSeriesï¼Œå€¼è¶Šä½è¡¨ç¤ºä¸€è‡´æ€§è¶Šé«˜ï¼ŒèŒƒå›´[0,1]
    """
    q3 = df.apply(lambda x: np.nanquantile(x, 0.75), axis=1)
    q1 = df.apply(lambda x: np.nanquantile(x, 0.25), axis=1)
    return q3 - q1

def cs_mad(df):
    """
    è®¡ç®—æˆªé¢å¹³å‡ç»å¯¹åå·®
    è¿”å›ï¼šSeriesï¼Œå€¼è¶Šä½è¡¨ç¤ºä¸€è‡´æ€§è¶Šé«˜ï¼ŒèŒƒå›´[0,0.5]
    """
    return df.apply(lambda x: np.nanmean(np.abs(x - np.nanmean(x))), axis=1)

def cs_consensus_index(df):
    """
    è®¡ç®—ç»¼åˆä¸€è‡´æ€§æŒ‡æ ‡
    è¿”å›ï¼šSeriesï¼Œæ­£å€¼æ¥è¿‘1ï¼šå¼ºçƒˆä¸€è‡´åå¤šï¼Œè´Ÿå€¼æ¥è¿‘-1ï¼šå¼ºçƒˆä¸€è‡´åç©ºï¼Œæ¥è¿‘0ï¼šæ— æ˜æ˜¾ä¸€è‡´æ€§ï¼ŒèŒƒå›´[-1,1]
    """
    # è®¡ç®—å¹³å‡å€¼ç›¸å¯¹äº0.5çš„ä½ç½®
    mean_position = csmean(df) - 0.5
    # è®¡ç®—å¹³å‡ç»å¯¹åå·®ï¼ˆè¶Šå°è¡¨ç¤ºä¸€è‡´æ€§è¶Šé«˜ï¼‰
    mad = df.apply(lambda x: np.nanmean(np.abs(x - np.nanmean(x))), axis=1)
    # è®¡ç®—ä¸€è‡´æ€§å¼ºåº¦ï¼ˆ1å‡å»å½’ä¸€åŒ–MADï¼‰
    consensus_strength = 1 - (mad / 0.5)
    # ç»¼åˆæŒ‡æ ‡ï¼šæ–¹å‘ * å¼ºåº¦
    return (mean_position / 0.5) * consensus_strength

def cs_above_threshold(df, threshold=0.5):
    """
    è®¡ç®—æˆªé¢ä¸­é«˜äºé˜ˆå€¼çš„æ¯”ä¾‹
    è¿”å›ï¼šSeriesï¼Œè¡¨ç¤ºé«˜äºé˜ˆå€¼çš„æ¯”ä¾‹ï¼ŒèŒƒå›´[0,1]
    """
    return df.apply(lambda x: np.mean(x > threshold), axis=1)

def cs_below_threshold(df, threshold=0.5):
    """
    è®¡ç®—æˆªé¢ä¸­ä½äºé˜ˆå€¼çš„æ¯”ä¾‹
    è¿”å›ï¼šSeriesï¼Œè¡¨ç¤ºä½äºé˜ˆå€¼çš„æ¯”ä¾‹ï¼ŒèŒƒå›´[0,1]
    """
    return df.apply(lambda x: np.mean(x < threshold), axis=1)


# %%
import numpy as np
import pandas as pd

def cs_breadth(df):
    """
    è®¡ç®—èµ„é‡‘æµå¹¿åº¦ï¼š(å‡€æµå…¥è‚¡ç¥¨æ•°é‡-å‡€æµå‡ºè‚¡ç¥¨æ•°é‡) / æ€»è‚¡ç¥¨æ•°é‡
    
    Parameters:
    df (pd.DataFrame): è¾“å…¥çš„èµ„é‡‘æµæ•°æ®ï¼ˆä¹°-å–ï¼‰ï¼Œè¡Œä¸ºæ—¶é—´ï¼Œåˆ—ä¸ºè‚¡ç¥¨
    
    Returns:
    pd.Series: æ¯è¡Œçš„å¹¿åº¦æŒ‡æ ‡ï¼ŒèŒƒå›´[-1, 1]
    """
    # åˆ›å»ºæœ‰æ•ˆå€¼æ©ç 
    valid_mask = ~df.isna()
    
    # è®¡ç®—å‡€æµå…¥å’Œå‡€æµå‡ºæ•°é‡
    inflow_count = (df > 0).sum(axis=1)
    outflow_count = (df < 0).sum(axis=1)
    total_count = valid_mask.sum(axis=1)
    
    # é¿å…é™¤é›¶
    breadth = (inflow_count - outflow_count) / total_count.replace(0, np.nan)
    
    return breadth


def cs_hhi(df):
    """
    è®¡ç®—èµ„é‡‘æµçš„HHIï¼ˆèµ«èŠ¬è¾¾å°”æŒ‡æ•°ï¼‰
    HHI = sum((ä¸ªè‚¡èµ„é‡‘æµå æ¯”)^2)
    
    Parameters:
    df (pd.DataFrame): è¾“å…¥çš„èµ„é‡‘æµæ•°æ®ï¼Œè¡Œä¸ºæ—¶é—´ï¼Œåˆ—ä¸ºè‚¡ç¥¨
    
    Returns:
    pd.Series: æ¯è¡Œçš„HHIæŒ‡æ ‡ï¼ŒèŒƒå›´[0, 1]
    """
    # è®¡ç®—ç»å¯¹å€¼
    abs_df = df.abs()
    
    # è®¡ç®—æ¯è¡Œæ€»å’Œ
    row_sums = abs_df.sum(axis=1)
    
    # è®¡ç®—å æ¯”çŸ©é˜µ
    shares = abs_df.div(row_sums, axis=0)
    
    # è®¡ç®—HHI
    hhi = (shares ** 2).sum(axis=1)
    
    # å¤„ç†æ€»å’Œä¸º0çš„æƒ…å†µ
    hhi = hhi.where(row_sums > 0, np.nan)
    
    return hhi


def cs_hhi_weighted(df, weights):
    """
    è®¡ç®—æƒé‡å½’ä¸€åŒ–çš„èµ„é‡‘æµHHI
    å…ˆå°†ä¸ªè‚¡èµ„é‡‘æµé™¤ä»¥æˆåˆ†è‚¡æƒé‡ï¼Œå†è®¡ç®—HHI
    
    Parameters:
    df (pd.DataFrame): è¾“å…¥çš„èµ„é‡‘æµæ•°æ®ï¼Œè¡Œä¸ºæ—¶é—´ï¼Œåˆ—ä¸ºè‚¡ç¥¨
    weights (pd.DataFrame): æƒé‡æ•°æ®ï¼Œéœ€è¦ä¸dfå¯¹é½
    
    Returns:
    pd.Series: æ¯è¡Œçš„åŠ æƒHHIæŒ‡æ ‡
    """
    # åˆ›å»ºæœ‰æ•ˆå€¼æ©ç 
    valid_mask = df.notna() & weights.notna() & (weights > 0)
    
    # æƒé‡å½’ä¸€åŒ–èµ„é‡‘æµ
    normalized_flow = df / weights
    
    # åªä¿ç•™æœ‰æ•ˆå€¼
    normalized_flow = normalized_flow.where(valid_mask, 0)
    
    # è®¡ç®—ç»å¯¹å€¼
    abs_normalized = normalized_flow.abs()
    
    # è®¡ç®—æ¯è¡Œæ€»å’Œ
    row_sums = abs_normalized.sum(axis=1)
    
    # è®¡ç®—å æ¯”
    shares = abs_normalized.div(row_sums, axis=0)
    
    # è®¡ç®—HHI
    hhi = (shares ** 2).sum(axis=1)
    
    # å¤„ç†æ— æ•ˆæƒ…å†µ
    hhi = hhi.where(row_sums > 0, np.nan)
    
    return hhi


def cs_hhi_positive(df):
    """
    è®¡ç®—ä»…è€ƒè™‘æ­£èµ„é‡‘æµçš„HHI
    
    Parameters:
    df (pd.DataFrame): è¾“å…¥çš„èµ„é‡‘æµæ•°æ®ï¼Œè¡Œä¸ºæ—¶é—´ï¼Œåˆ—ä¸ºè‚¡ç¥¨
    
    Returns:
    pd.Series: æ¯è¡Œçš„æ­£å‘HHIæŒ‡æ ‡
    """
    # åªä¿ç•™æ­£å€¼
    positive_df = df.where(df > 0, 0)
    
    # è®¡ç®—æ¯è¡Œæ€»å’Œ
    row_sums = positive_df.sum(axis=1)
    
    # è®¡ç®—å æ¯”
    shares = positive_df.div(row_sums, axis=0)
    
    # è®¡ç®—HHI
    hhi = (shares ** 2).sum(axis=1)
    
    # å¤„ç†æ€»å’Œä¸º0çš„æƒ…å†µ
    hhi = hhi.where(row_sums > 0, np.nan)
    
    return hhi


def cs_hhi_negative(df):
    """
    è®¡ç®—ä»…è€ƒè™‘è´Ÿèµ„é‡‘æµçš„HHI
    
    Parameters:
    df (pd.DataFrame): è¾“å…¥çš„èµ„é‡‘æµæ•°æ®ï¼Œè¡Œä¸ºæ—¶é—´ï¼Œåˆ—ä¸ºè‚¡ç¥¨
    
    Returns:
    pd.Series: æ¯è¡Œçš„è´Ÿå‘HHIæŒ‡æ ‡
    """
    # åªä¿ç•™è´Ÿå€¼çš„ç»å¯¹å€¼
    negative_df = (-df).where(df < 0, 0)
    
    # è®¡ç®—æ¯è¡Œæ€»å’Œ
    row_sums = negative_df.sum(axis=1)
    
    # è®¡ç®—å æ¯”
    shares = negative_df.div(row_sums, axis=0)
    
    # è®¡ç®—HHI
    hhi = (shares ** 2).sum(axis=1)
    
    # å¤„ç†æ€»å’Œä¸º0çš„æƒ…å†µ
    hhi = hhi.where(row_sums > 0, np.nan)
    
    return hhi


def cs_breadth_positive(df):
    """
    è®¡ç®—æ­£å‘èµ„é‡‘æµå¹¿åº¦ï¼šå‡€æµå…¥è‚¡ç¥¨æ•°é‡ / æ€»è‚¡ç¥¨æ•°é‡
    
    Parameters:
    df (pd.DataFrame): è¾“å…¥çš„èµ„é‡‘æµæ•°æ®ï¼Œè¡Œä¸ºæ—¶é—´ï¼Œåˆ—ä¸ºè‚¡ç¥¨
    
    Returns:
    pd.Series: æ¯è¡Œçš„æ­£å‘å¹¿åº¦æŒ‡æ ‡ï¼ŒèŒƒå›´[0, 1]
    """
    valid_mask = ~df.isna()
    inflow_count = (df > 0).sum(axis=1)
    total_count = valid_mask.sum(axis=1)
    
    return inflow_count / total_count.replace(0, np.nan)


def cs_breadth_negative(df):
    """
    è®¡ç®—è´Ÿå‘èµ„é‡‘æµå¹¿åº¦ï¼šå‡€æµå‡ºè‚¡ç¥¨æ•°é‡ / æ€»è‚¡ç¥¨æ•°é‡
    
    Parameters:
    df (pd.DataFrame): è¾“å…¥çš„èµ„é‡‘æµæ•°æ®ï¼Œè¡Œä¸ºæ—¶é—´ï¼Œåˆ—ä¸ºè‚¡ç¥¨
    
    Returns:
    pd.Series: æ¯è¡Œçš„è´Ÿå‘å¹¿åº¦æŒ‡æ ‡ï¼ŒèŒƒå›´[0, 1]
    """
    valid_mask = ~df.isna()
    outflow_count = (df < 0).sum(axis=1)
    total_count = valid_mask.sum(axis=1)
    
    return outflow_count / total_count.replace(0, np.nan)


def cs_diffusion_positive(df):
    """
    è®¡ç®—æ­£å‘èµ„é‡‘æµæ‰©æ•£æŒ‡æ ‡ï¼šBC_pos Ã— (1 - HHI_pos)
    
    Parameters:
    df (pd.DataFrame): è¾“å…¥çš„èµ„é‡‘æµæ•°æ®ï¼Œè¡Œä¸ºæ—¶é—´ï¼Œåˆ—ä¸ºè‚¡ç¥¨
    
    Returns:
    pd.Series: æ¯è¡Œçš„æ­£å‘æ‰©æ•£æŒ‡æ ‡
    """
    breadth = cs_breadth_positive(df)
    concentration = cs_hhi_positive(df)
    return breadth * (1 - concentration)


def cs_diffusion_negative(df):
    """
    è®¡ç®—è´Ÿå‘èµ„é‡‘æµæ‰©æ•£æŒ‡æ ‡ï¼šBC_neg Ã— (1 - HHI_neg)
    
    Parameters:
    df (pd.DataFrame): è¾“å…¥çš„èµ„é‡‘æµæ•°æ®ï¼Œè¡Œä¸ºæ—¶é—´ï¼Œåˆ—ä¸ºè‚¡ç¥¨
    
    Returns:
    pd.Series: æ¯è¡Œçš„è´Ÿå‘æ‰©æ•£æŒ‡æ ‡
    """
    breadth = cs_breadth_negative(df)
    concentration = cs_hhi_negative(df)
    return breadth * (1 - concentration)