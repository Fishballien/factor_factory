# -*- coding: utf-8 -*-
"""
Created on Tue Dec 31 16:47:07 2024

@author: Xintang Zheng

æ˜Ÿæ˜Ÿ: â˜… â˜† âœª âœ© ğŸŒŸ â­ âœ¨ ğŸŒ  ğŸ’« â­ï¸
å‹¾å‹¾å‰å‰: âœ“ âœ” âœ• âœ– âœ… â
æŠ¥è­¦å•¦: âš  â“˜ â„¹ â˜£
ç®­å¤´: â” âœ â™ â¤ â¥ â†© â†ª
emoji: ğŸ”” â³ â° ğŸ”’ ğŸ”“ ğŸ›‘ ğŸš« â— â“ âŒ â­• ğŸš€ ğŸ”¥ ğŸ’§ ğŸ’¡ ğŸµ ğŸ¶ ğŸ§­ ğŸ“… ğŸ¤” ğŸ§® ğŸ”¢ ğŸ“Š ğŸ“ˆ ğŸ“‰ ğŸ§  ğŸ“

"""
# %%
'''
fr sk: è¿™ä¸ªè¡¨çš„æ•°æ®å¯èƒ½æ˜¯2022-05-26å¼€é€šçš„ï¼Œè¿™ä¹‹åçš„æ•°æ®éƒ½æ˜¯æœˆåº•å½“å¤©çš„æ™šä¸Šå…«ç‚¹åŠå·¦å³æ›´æ–°
 -> éš”æ—¥0ç‚¹æ›´æ–°åº”è¯¥æ²¡é—®é¢˜
'''
# %%
import sys
import pymysql
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
import json
import time


# %% add sys path
file_path = Path(__file__).resolve()
file_dir = file_path.parents[0]
project_dir = file_path.parents[1]
sys.path.append(str(project_dir))


# %% import self_defined
from utils.dateutils import (get_cffex_trading_days_by_date_range, get_next_trading_day, 
                             get_previous_n_trading_day, is_last_trading_day_of_month)


# %%
def fetch_database(sql, database="TonglianData"):
    conn = pymysql.connect(host='172.16.30.20',
                           user='reader',
                           password='Qingchun123.com',
                           database=database)

    cur = conn.cursor()
    cur.execute(sql)
    output = cur.fetchall()
    # print(output)
    # conn.close()
    data = pd.read_sql(sql, conn) # , index_col='brand_id'
    return data # output


# =============================================================================
# def get_index_weight(idxname="000852"):
#     sql = """
#     SELECT
#         a.SECURITY_ID,
#         b.TICKER_SYMBOL AS INDEX_SYMBOL,
#         b.SEC_SHORT_NAME AS INDEX_NAME,
#         a.CONS_ID,
#         c.TICKER_SYMBOL AS STOCK_SYMBOL,
#         c.SEC_SHORT_NAME AS STOCK_NAME,
#         c.EXCHANGE_CD,
#         a.EFF_DATE,
#         a.WEIGHT,
#         a.UPDATE_TIME
#     FROM idx_weight a 
#         LEFT JOIN md_security b ON a.SECURITY_ID=b.SECURITY_ID
#         LEFT JOIN md_security c ON a.CONS_ID=c.SECURITY_ID
#     WHERE b.TICKER_SYMBOL='{idxname}' /*è¾“å…¥éœ€æŸ¥è¯¢çš„æŒ‡æ•°ä»£ç */
#     """.format(idxname=idxname)
#     data = fetch_database(sql)
#     return data
# =============================================================================

def get_index_weight(idxname="000852"):
    sql = """
    SELECT
        a.SECURITY_ID,
        b.TICKER_SYMBOL AS INDEX_SYMBOL,
        b.SEC_SHORT_NAME AS INDEX_NAME,
        a.CONS_ID,
        c.TICKER_SYMBOL AS STOCK_SYMBOL,
        c.SEC_SHORT_NAME AS STOCK_NAME,
        c.EXCHANGE_CD,
        a.EFF_DATE,
        a.WEIGHT,
        a.HERMESFIRSTTIME,
        a.HERMESUPTIME,
        a.UPDATE_TIME
    FROM idx_weight a 
        LEFT JOIN md_security b ON a.SECURITY_ID=b.SECURITY_ID
        LEFT JOIN md_security c ON a.CONS_ID=c.SECURITY_ID
    WHERE b.TICKER_SYMBOL='{idxname}' /*è¾“å…¥éœ€æŸ¥è¯¢çš„æŒ‡æ•°ä»£ç */
    """.format(idxname=idxname)
    data = fetch_database(sql)
    return data


def get_index_weight2(idxname="932000"):
    sql = """
    SELECT
        a.SECURITY_ID,
        b.TICKER_SYMBOL AS INDEX_SYMBOL,
        b.SEC_SHORT_NAME AS INDEX_NAME,
        a.CONS_ID,
        c.TICKER_SYMBOL AS STOCK_SYMBOL,
        c.SEC_SHORT_NAME AS STOCK_NAME,
        c.EXCHANGE_CD,
        a.EFF_DATE,
        a.WEIGHT,
        a.UPDATE_TIME
    FROM csi_idxm_wt_ashare a 
        LEFT JOIN md_security b ON a.SECURITY_ID=b.SECURITY_ID
        LEFT JOIN md_security c ON a.CONS_ID=c.SECURITY_ID
    WHERE b.TICKER_SYMBOL='{idxname}' /*è¾“å…¥éœ€æŸ¥è¯¢çš„æŒ‡æ•°ä»£ç */
    """.format(idxname=idxname)
    data = fetch_database(sql)
    return data

def get_index_weight3(idxname="932000"):
    sql = """
    SELECT
        a.SECURITY_ID,
        b.TICKER_SYMBOL AS INDEX_SYMBOL,
        b.SEC_SHORT_NAME AS INDEX_NAME,
        a.CONS_ID,
        c.TICKER_SYMBOL AS STOCK_SYMBOL,
        c.SEC_SHORT_NAME AS STOCK_NAME,
        c.EXCHANGE_CD,
        a.EFF_DATE,
        a.WEIGHT,
        a.UPDATE_TIME
    FROM idx_cons_csi a 
        LEFT JOIN md_security b ON a.SECURITY_ID=b.SECURITY_ID
        LEFT JOIN md_security c ON a.CONS_ID=c.SECURITY_ID
    WHERE b.TICKER_SYMBOL='{idxname}' /*è¾“å…¥éœ€æŸ¥è¯¢çš„æŒ‡æ•°ä»£ç */
    """.format(idxname=idxname)
    data = fetch_database(sql)
    return data


# =============================================================================
# def index_weight_data(idxcode, target_date, save_dir=''):
#     newdata = get_index_weight(idxcode)  
#     # breakpoint()
#     if len(newdata) == 0: # zz2000 è·å–æ¸ é“ä¸ä¸€æ ·
#         newdata = get_index_weight2(idxcode)
# 
#     newdata.to_parquet(save_dir / f'{idxcode}_sql_org.parquet')
#     
#     newdata['con_code'] = newdata['STOCK_SYMBOL'] + "." + newdata["EXCHANGE_CD"]
#     newdata = newdata.rename(columns={
#         'EFF_DATE': 'trade_date',
#         'WEIGHT': 'weight',
#         })[['con_code', 'trade_date', 'weight']]
#     newdata.to_parquet(save_dir / f'{idxcode}_index_weight.parquet')
#     
#     newdata['weight'] = newdata['weight'].astype(np.float64)
#     data = newdata.pivot(index='trade_date', columns='con_code',values='weight').fillna(0)
#     data.index = pd.to_datetime(data.index, format='%Y-%m-%d')
#     # daily_index = pd.date_range(start=data.index.min(), end=target_date, freq='D') # data.index.max()
#     # breakpoint()
#     daily_index = get_cffex_trading_days_by_date_range(start_date=data.index.min().date(), end_date=target_date)
#     daily_index = pd.to_datetime([get_next_trading_day(dt) for dt in daily_index])
#     daily_weights = data.reindex(daily_index, method='ffill').fillna(0)
#     # daily_weights.index = daily_weights.index.map(lambda dt: get_next_trading_day(dt))
#     daily_weights.to_parquet(save_dir / f'{idxcode}.parquet')
#     
#     return daily_weights
# =============================================================================


def index_weight_data(idxcode, target_date, save_dir='', check_if_inc=False):
    # è·å–æ–°æ•°æ®
    newdata = get_index_weight(idxcode)  
    # breakpoint()
    if len(newdata) == 0:  # zz2000 è·å–æ¸ é“ä¸ä¸€æ ·
        newdata = get_index_weight2(idxcode)
    newdata.to_parquet(save_dir / f'{idxcode}_sql_org.parquet')
    
    # å¤„ç†æ–°æ•°æ®
    newdata['con_code'] = newdata['STOCK_SYMBOL'] + "." + newdata["EXCHANGE_CD"]
    newdata = newdata.rename(columns={
        'EFF_DATE': 'trade_date',
        'WEIGHT': 'weight',
        })[['con_code', 'trade_date', 'weight']]
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ—§çš„æƒé‡æ•°æ®æ–‡ä»¶
    old_weight_file = save_dir / f'{idxcode}_index_weight.parquet'
    if old_weight_file.exists():
        # è¯»å–æ—§æ•°æ®
        olddata = pd.read_parquet(old_weight_file)
        
        # æ‰¾å‡ºæ—§æ•°æ®ä¸­å­˜åœ¨çš„æ—¥æœŸ
        old_dates = set(olddata['trade_date'].unique())
        
        # ç­›é€‰å‡ºæ—§æ•°æ®ä¸­ä¸å­˜åœ¨çš„æ–°æ•°æ®æ—¥æœŸ
        new_incremental = newdata[~newdata['trade_date'].isin(old_dates)]
        
        if check_if_inc and len(new_incremental) == 0:
            return 'NOINC', None
        
        # åˆå¹¶æ—§æ•°æ®å’Œå¢é‡æ–°æ•°æ®
        mergeddata = pd.concat([olddata, new_incremental], ignore_index=True)
    else:
        # å¦‚æœæ²¡æœ‰æ—§æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨æ–°æ•°æ®
        mergeddata = newdata
    
    # ä¿å­˜æ›´æ–°åçš„æƒé‡æ•°æ®
    mergeddata.to_parquet(save_dir / f'{idxcode}_index_weight.parquet')
    
    # ç»§ç»­å¤„ç†æˆå®½æ ¼å¼æ•°æ®
    mergeddata['weight'] = mergeddata['weight'].astype(np.float64)
    data = mergeddata.pivot(index='trade_date', columns='con_code', values='weight').fillna(0)
    data.index = pd.to_datetime(data.index, format='%Y-%m-%d')
    
    # ç”Ÿæˆæ—¥æœŸç´¢å¼•
    daily_index = get_cffex_trading_days_by_date_range(start_date=data.index.min().date(), end_date=target_date)
    daily_index = pd.to_datetime([get_next_trading_day(dt) for dt in daily_index])
    
    # å¡«å……æ¯æ—¥æƒé‡æ•°æ®
    daily_weights = data.reindex(daily_index, method='ffill').fillna(0)
    daily_weights.to_parquet(save_dir / f'{idxcode}.parquet')
    
    return 'SUCCESS', daily_weights
    

# %%
if __name__ == "__main__":
    delay = 0
    # index_code = ['000300']
    index_code = ["000016", "000300", "000905", "000852", "932000", "000985"]
    # index_code = [
    #     "512050", "510300", "159845", "159915", 
    #     "159338", "588000", "588190", "562500", "512480", 
    #     "588200", "159819", "159995", "159992", "159869", "512800"
    #     ]
    # save_dir = Path(r'D:/CNIndexFutures/timeseries/factor_factory/sample_data/weights_matrix_fr_sql')
    save_dir = Path(r'/mnt/data1/stockweights')
    flag_dir = save_dir / 'flag'
    save_dir.mkdir(parents=True, exist_ok=True)
    flag_dir.mkdir(parents=True, exist_ok=True)
    
    
    date_today = datetime.today().date()
    target_date = get_previous_n_trading_day(date_today, delay)
    is_last = is_last_trading_day_of_month(target_date)
    if is_last:
        time.sleep(60*60*4)
    
    if not is_last:
        wgt_dict = {}
        for idxcode in index_code: #["000016", "000300", "000905", "000852", "932000", "000985"]:  
            wgt_dict[idxcode] = index_weight_data(idxcode, target_date, save_dir)
        with open(flag_dir / f'{target_date}.json', 'w') as f:
            json.dump({}, f)
    else:
        wgt_dict = {}
        status_dict = {idxcode: '' for idxcode in index_code}
        
        while True:
            # Check all index codes
            for idxcode in index_code:
                if status_dict[idxcode] != 'SUCCESS':
                    status, res = index_weight_data(idxcode, target_date, save_dir, check_if_inc=True)
                    status_dict[idxcode] = status
                    if status == 'SUCCESS':
                        wgt_dict[idxcode] = res
            
            # Check if all statuses are 'SUCCESS'
            if all(status == 'SUCCESS' for status in status_dict.values()):
                break
            else:
                # Sleep for 5 minutes if not all are success
                time.sleep(300)  # 5 minutes in seconds
        
        # After successful completion, save the flag file
        with open(flag_dir / f'{target_date}.json', 'w') as f:
            json.dump({}, f)
            
      
