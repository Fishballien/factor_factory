# -*- coding: utf-8 -*-
"""
Created on Tue Nov 12 16:50:12 2024

@author: Xintang Zheng

æ˜Ÿæ˜Ÿ: â˜… â˜† âœª âœ© ðŸŒŸ â­ âœ¨ ðŸŒ  ðŸ’« â­ï¸
å‹¾å‹¾å‰å‰: âœ“ âœ” âœ• âœ– âœ… âŽ
æŠ¥è­¦å•¦: âš  â“˜ â„¹ â˜£
ç®­å¤´: âž” âžœ âž™ âž¤ âž¥ â†© â†ª
emoji: ðŸ”” â³ â° ðŸ”’ ðŸ”“ ðŸ›‘ ðŸš« â— â“ âŒ â­• ðŸš€ ðŸ”¥ ðŸ’§ ðŸ’¡ ðŸŽµ ðŸŽ¶ ðŸ§­ ðŸ“… ðŸ¤” ðŸ§® ðŸ”¢ ðŸ“Š ðŸ“ˆ ðŸ“‰ ðŸ§  ðŸ“

"""
# %% imports
from pathlib import Path
import pandas as pd
import numpy as np
from tqdm import tqdm
from joblib import Parallel, delayed


from trans_operators import imb01
from utils.market import index_mapping
from utils.speedutils import timeit


# %%
sides = ('bid', 'ask')


# %%
def replace_column_suffixes(data, old_suffix1=".XSHE", new_suffix1=".SZ", old_suffix2=".XSHG", new_suffix2=".SH"):
    """
    æ›¿æ¢ DataFrame åˆ—åçš„åŽç¼€ï¼š
    - å°†æŒ‡å®šçš„ old_suffix1 æ›¿æ¢ä¸º new_suffix1
    - å°†æŒ‡å®šçš„ old_suffix2 æ›¿æ¢ä¸º new_suffix2

    å‚æ•°:
    data (pd.DataFrame): åŒ…å«è‚¡ç¥¨ä»£ç çš„ DataFrameï¼Œåˆ—åä¸­å«æœ‰éœ€è¦æ›¿æ¢çš„åŽç¼€ã€‚
    old_suffix1 (str): è¦æ›¿æ¢çš„ç¬¬ä¸€ä¸ªæ—§åŽç¼€ï¼Œé»˜è®¤ä¸º ".XSHE"ã€‚
    new_suffix1 (str): æ›¿æ¢çš„ç¬¬ä¸€ä¸ªæ–°åŽç¼€ï¼Œé»˜è®¤ä¸º ".SZ"ã€‚
    old_suffix2 (str): è¦æ›¿æ¢çš„ç¬¬äºŒä¸ªæ—§åŽç¼€ï¼Œé»˜è®¤ä¸º ".XSHG"ã€‚
    new_suffix2 (str): æ›¿æ¢çš„ç¬¬äºŒä¸ªæ–°åŽç¼€ï¼Œé»˜è®¤ä¸º ".SH"ã€‚

    è¿”å›ž:
    pd.DataFrame: åˆ—ååŽç¼€å·²æ›¿æ¢çš„æ–° DataFrameã€‚
    """
    # æ›¿æ¢æŒ‡å®šçš„åˆ—ååŽç¼€
    data.columns = data.columns.str.replace(old_suffix1, new_suffix1).str.replace(old_suffix2, new_suffix2)
    return data


# =============================================================================
# @timeit
# def apply_daily_weights_to_timeseries(data, daily_weights):
#     """
#     å°†æ¯æ—¥æƒé‡åº”ç”¨åˆ°æ›´é«˜é¢‘çš„æ—¶é—´åºåˆ—æ•°æ®ï¼ˆä¾‹å¦‚åˆ†é’Ÿã€ç§’çº§ç­‰ï¼‰ï¼Œ
#     æ ¹æ®æ—¥æœŸå°†æ¯æ—¥æƒé‡æ‰©å±•åˆ°ç›®æ ‡æ—¶é—´é¢‘çŽ‡æ•°æ®ã€‚
#     å¯¹äºŽ daily_weights ä¸­æ²¡æœ‰çš„è‚¡ç¥¨ä»£ç åˆ—ï¼Œå¡«å……æƒé‡ä¸º 0ã€‚
# 
#     å‚æ•°:
#     data (pd.DataFrame): é«˜é¢‘æ—¶é—´åºåˆ—æ•°æ®ï¼Œè¡Œæ˜¯æ—¶é—´æˆ³ï¼Œåˆ—æ˜¯è‚¡ç¥¨ä»£ç ã€‚
#     daily_weights (pd.DataFrame): æ¯æ—¥æƒé‡æ•°æ®ï¼Œè¡Œæ˜¯æ—¥æœŸï¼Œåˆ—æ˜¯è‚¡ç¥¨ä»£ç ã€‚
# 
#     è¿”å›ž:
#     pd.DataFrame: è°ƒæ•´åŽçš„é«˜é¢‘æ—¶é—´åºåˆ—æ•°æ®ã€‚
#     """
#     # ç¡®ä¿ daily_weights çš„ç´¢å¼•æ˜¯æ—¥æœŸæ ¼å¼
#     daily_weights.index = pd.to_datetime(daily_weights.index)
#     
#     # æå– data çš„æ—¥æœŸéƒ¨åˆ†ç”¨äºŽåŒ¹é…
#     data_dates = data.index.normalize()
#     
#     # æ‰©å±• daily_weights åˆ—ï¼Œä½¿å…¶åŒ…å« data ä¸­çš„æ‰€æœ‰åˆ—ï¼Œä¸å­˜åœ¨çš„åˆ—å¡«å…… 0
#     expanded_weights = daily_weights.reindex(columns=data.columns, fill_value=0)
#     
#     # å°†æ¯æ—¥æƒé‡æ‰©å±•åˆ°ç›®æ ‡æ—¶é—´é¢‘çŽ‡çš„æ•°æ®
#     expanded_weights = expanded_weights.reindex(data_dates, method='ffill')
#     
#     # é€å…ƒç´ ç›¸ä¹˜ï¼Œåº”ç”¨æƒé‡
#     adjusted_data = data.mul(expanded_weights.values, axis=0)
#     
#     return adjusted_data
# =============================================================================


# =============================================================================
# @timeit
# def apply_daily_weights_to_timeseries(data, daily_weights):
#     """
#     ä½¿ç”¨ NumPy ä¼˜åŒ–æ–¹æ³•ï¼Œå°†æ¯æ—¥æƒé‡ç›´æŽ¥åº”ç”¨åˆ°é«˜é¢‘æ—¶é—´åºåˆ—æ•°æ®ã€‚
# 
#     å‚æ•°:
#     data (pd.DataFrame): é«˜é¢‘æ—¶é—´åºåˆ—æ•°æ®ï¼Œè¡Œæ˜¯æ—¶é—´æˆ³ï¼Œåˆ—æ˜¯è‚¡ç¥¨ä»£ç ã€‚
#     daily_weights (pd.DataFrame): æ¯æ—¥æƒé‡æ•°æ®ï¼Œè¡Œæ˜¯æ—¥æœŸï¼Œåˆ—æ˜¯è‚¡ç¥¨ä»£ç ã€‚
# 
#     è¿”å›ž:
#     pd.DataFrame: è°ƒæ•´åŽçš„é«˜é¢‘æ—¶é—´åºåˆ—æ•°æ®ã€‚
#     """
#     # ç¡®ä¿ daily_weights ç´¢å¼•ä¸ºæ—¥æœŸæ ¼å¼
#     daily_weights.index = pd.to_datetime(daily_weights.index)
#     
#     # æå– data çš„æ—¥æœŸéƒ¨åˆ†å¹¶æ‰¾åˆ°å¯¹åº”æƒé‡
#     data_dates = data.index.normalize()
#     unique_dates = np.unique(data_dates)
#     
#     # æ‰©å±•æƒé‡åˆ°æ‰€æœ‰æ—¥æœŸ
#     expanded_weights = daily_weights.reindex(unique_dates, fill_value=0).ffill().reindex(columns=data.columns, fill_value=0)
# 
#     # è½¬ä¸º NumPy æ•°ç»„æ“ä½œ
#     data_array = data.to_numpy()
#     weights_array = expanded_weights.loc[data_dates].to_numpy()
# 
#     # åº”ç”¨æƒé‡
#     adjusted_array = data_array * weights_array
# 
#     # è½¬å›ž DataFrame
#     return pd.DataFrame(adjusted_array, index=data.index, columns=data.columns)
# =============================================================================


@timeit
def apply_daily_weights_to_timeseries(data, daily_weights):
    """
    å°†æ¯æ—¥æƒé‡åº”ç”¨åˆ°æ›´é«˜é¢‘çš„æ—¶é—´åºåˆ—æ•°æ®ï¼ˆä¾‹å¦‚åˆ†é’Ÿã€ç§’çº§ç­‰ï¼‰ï¼Œ
    æ ¹æ®æ—¥æœŸå°†æ¯æ—¥æƒé‡æ‰©å±•åˆ°ç›®æ ‡æ—¶é—´é¢‘çŽ‡æ•°æ®ã€‚
    å¯¹äºŽ daily_weights ä¸­æ²¡æœ‰çš„è‚¡ç¥¨ä»£ç åˆ—ï¼Œå¡«å……æƒé‡ä¸º 0ã€‚

    å‚æ•°:
    data (pd.DataFrame): é«˜é¢‘æ—¶é—´åºåˆ—æ•°æ®ï¼Œè¡Œæ˜¯æ—¶é—´æˆ³ï¼Œåˆ—æ˜¯è‚¡ç¥¨ä»£ç ã€‚
    daily_weights (pd.DataFrame): æ¯æ—¥æƒé‡æ•°æ®ï¼Œè¡Œæ˜¯æ—¥æœŸï¼Œåˆ—æ˜¯è‚¡ç¥¨ä»£ç ã€‚

    è¿”å›ž:
    pd.DataFrame: è°ƒæ•´åŽçš„é«˜é¢‘æ—¶é—´åºåˆ—æ•°æ®ã€‚
    """
    daily_weights.index = pd.to_datetime(daily_weights.index)
    data_dates = data.index.normalize()
    data = data.reindex(columns=daily_weights.columns, fill_value=0)
    expanded_weights = daily_weights.reindex(data_dates, method='ffill')
    adjusted_data = data.mul(expanded_weights.values, axis=0)
    return adjusted_data


# =============================================================================
# @timeit
# def get_mean_by_row(df):
#     return df.mean(axis=1)
# =============================================================================


# =============================================================================
# @timeit
# def get_mean_by_row(df, n_jobs=256):
#     """
#     ä½¿ç”¨ joblib å¹¶è¡Œè®¡ç®—æ¯è¡Œå‡å€¼ã€‚
#     
#     å‚æ•°:
#     df (pd.DataFrame): è¾“å…¥çš„ DataFrameã€‚
#     n_jobs (int): å¹¶è¡Œä½œä¸šçš„æ ¸æ•°ã€‚
#     
#     è¿”å›ž:
#     np.ndarray: æ¯è¡Œçš„å‡å€¼ã€‚
#     """
#     # å°† DataFrame æ‹†åˆ†ä¸º n_jobs ä»½
#     chunks = np.array_split(df, n_jobs)
# 
#     # å¹¶è¡Œè®¡ç®—æ¯è¡Œå‡å€¼
#     results = Parallel(n_jobs=n_jobs)(
#         delayed(lambda x: x.mean(axis=1).to_numpy())(chunk) for chunk in chunks
#     )
#     
#     # åˆå¹¶ç»“æžœ
#     row_means = np.concatenate(results)
# 
#     # è½¬å›ž Seriesï¼Œä¿æŒç´¢å¼•ä¸€è‡´ï¼Œä¸æ·»åŠ  name
#     return pd.Series(row_means, index=df.index)
# =============================================================================


@timeit
def get_mean_by_row(df):
    """
    ä½¿ç”¨ NumPy çŸ©é˜µè®¡ç®— DataFrame æ¯è¡Œçš„å¹³å‡å€¼ã€‚
    
    å‚æ•°:
    df (pd.DataFrame): è¾“å…¥çš„ DataFrameã€‚
    
    è¿”å›ž:
    pd.Series: æ¯è¡Œçš„å¹³å‡å€¼ï¼Œç´¢å¼•ä¸ŽåŽŸå§‹ DataFrame ä¸€è‡´ã€‚
    """
    # è½¬ä¸º NumPy çŸ©é˜µå¹¶è®¡ç®—è¡Œå‡å€¼
    row_means = np.nanmean(df.to_numpy(), axis=1)
    
    # è½¬å›ž Pandas Seriesï¼Œä¿æŒç´¢å¼•ä¸€è‡´
    return pd.Series(row_means, index=df.index)


# %%
ind_dir = Path(r'D:\CNIndexFutures\timeseries\factor_factory\sample_data\indicators/test')
daily_weights_dir = Path(r'D:/CNIndexFutures/timeseries/factor_factory/sample_data/weights_matrix_fr_sql')
factor_dir = Path(r'D:/CNIndexFutures/timeseries/factor_factory/sample_data/factors/test')
# ind_dir = Path(r'/mnt/data1/xintang/lob_indicators/indv0_total_amount/cs')
# daily_weights_dir = Path(r'/mnt/data1/xintang/factor_factory/sample_data/weights_matrix')
# factor_dir = Path(r'/mnt/data1/xintang/factor_factory/sample_data/factors')
ind_name = 'l_amount'
index_list = ['hs300'] #list(index_mapping.keys())


# %%
ind_sides = {side: replace_column_suffixes(pd.read_parquet(ind_dir / f'{side}_{ind_name}.parquet')).resample('1min').asfreq()
             for side in sides}


# %%
daily_weights = {}
for index_name in index_list:
    index_code = index_mapping[index_name]
    daily_weights[index_code] = pd.read_parquet(daily_weights_dir / f'{index_code}.parquet')


# %% ver 1: wavg amount -> imb
imb_name1 = 'wavg_imb01'
res_ver1 = {}
# for index_name, daily_weight in tqdm(daily_weights.items(), desc='processing indexes'):
for index_name, daily_weight in daily_weights.items():
    wadj_sides = {side: apply_daily_weights_to_timeseries(ind_sides[side], daily_weight) for side in sides}
    wadj_mean_sides = {side: get_mean_by_row(wadj_sides[side]) for side in wadj_sides}
    res_ver1[index_name] = imb01(wadj_mean_sides['bid'], wadj_mean_sides['ask'])
df_ver1 = pd.DataFrame(res_ver1)
df_ver1.to_parquet(factor_dir / f'{ind_name}_{imb_name1}.parquet')


# %% ver 2: imb -> wavg
imb_name2 = 'imb01_wavg'
res_ver2 = {}
# for index_name, daily_weight in tqdm(daily_weights.items(), desc='processing indexes'):
for index_name, daily_weight in daily_weights.items():
    imb = imb01(ind_sides['bid'], ind_sides['ask'])
    wadj_imb = apply_daily_weights_to_timeseries(imb, daily_weight)
    res_ver2[index_name] = get_mean_by_row(wadj_imb)
df_ver2 = pd.DataFrame(res_ver2)
df_ver2.to_parquet(factor_dir / f'{ind_name}_{imb_name2}.parquet')
